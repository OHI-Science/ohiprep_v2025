---
title: "Workspace for troubleshooting data issues in NP FAO data"
author: "Anna Ramji"
date: "2024-08-26"
---



## Setup
(copied from STEP1a)
```{r}

knitr::opts_chunk$set(eval = FALSE)

# ======= Load packages ============
if (!require(librarian)) {
  install.packages("librarian")
  library(librarian)
}
librarian::shelf(
  ohicore, #devtools::install_github('ohi-science/ohicore@dev') #if relevant: restart session after reinstalling
  dplyr,
  stringr,
  tidyr,
  here,
  tidyverse,
  zoo,
  ggplot2,
  plotly,
  tictoc,
  RColorBrewer
)

# ======= Set directories ===========
# Update scenario year, set up programmatic scenario year updates
scen_year_number <- 2024
scen_year <- as.character(scen_year_number)
prev_scen_year <- as.character(scen_year_number - 1)
data_dir_year <- paste0("d", scen_year)
prev_data_dir_year <- paste0("d", prev_scen_year)
v_scen_year <- paste0("v", scen_year)

current_np_dir <- here::here("globalprep", "np", v_scen_year)

# Load FAO-specific user-defined functions
source(here::here("workflow", "R", "fao_fxn.R")) # function for cleaning FAO files
source(here::here("workflow", "R", "common.R")) # directory locations
source(here::here(current_np_dir, "R", "np_fxn.R")) # function for handling FAO commodity data specific to NP

```



```{r}
# Import new FAO data from FishStatJ download
dir_fao_data <- here::here(dir_M, "git-annex", "globalprep", "_raw_data", "FAO_commodities", data_dir_year)

files <- list.files(dir_fao_data, pattern = glob2rx('*.csv'), full.names = TRUE)


# Import last year's data for comparison

dir_fao_data_old <- here::here(dir_M, "git-annex", "globalprep", "_raw_data", "FAO_commodities", prev_data_dir_year)

files_old <- list.files(dir_fao_data_old, pattern = glob2rx('*.csv'), full.names = TRUE)

```


```{r}
f <- files[1] # un-comment and update to test individual files
  cat(sprintf('\n\n\n====\nfile: %s\n', basename(f)))
  
  #d <- read.csv(f, check.names = FALSE, strip.white = TRUE, stringsAsFactors = FALSE) # stringsAsFactors=T
  # checks names syntactically, strips leading and trailing whitespace, prevents conversion of characters to factors 
  
  d <- readr::read_csv(f) # makes this a tibble, not a dataframe (check with is_tibble(d))
  # ignore the warning here -- it's just letting you know about an empty final row (happened quietly in previous read.csv code)
  
  # Specifies that units are 'tonnes' if we are reading in the Commodities Quantity data csv, and 'usd' if we are reading in the Commodities Value data csv
  units <- c("tonnes", "usd")[str_detect(f, c("quant", "value"))] # detect unit name using lowercase American English
```



```{r check-quant-data}
# singapore_raw <- d %>% filter(`Reporting country (Name)` %in% c("Singapore")) %>% 
#   janitor::clean_names()

# check new quantity data ----

# filter, clean, tidy new quantity data
singapore_raw <- d %>% 
  janitor::clean_names() %>% 
  filter(reporting_country_name %in% c("Singapore"),
         trade_flow_name %in% c("Exports")) %>% 
  dplyr::select(-c(unit_name)) %>% # "Tonnes – net product weight" == TPW
    rename(country = reporting_country_name,
           commodity = commodity_name,
           trade = trade_flow_name) 

# filter to saltwater ornamentals 
singapore_ornamental_raw <- singapore_raw %>% 
  filter(str_detect(commodity, pattern = "Ornamental saltwater fish"))

singapore_ornamental_test <- singapore_raw %>% 
  filter(commodity %in% c("Ornamental saltwater fish", "Ornamental fish nei")) %>% 
  rename_with(~ gsub("x", "", .)) %>% # tidy up year column names (clean_names() added "x"s)
    pivot_longer(cols = -c(country, commodity, trade, unit),
                   names_to = "year", values_to = "value") %>% 
  mutate(year = as.numeric(year))

# pivot year columns
singapore_orn_new_pivot <- singapore_ornamental_raw %>% 
   rename_with(~ gsub("x", "", .)) %>% # tidy up year column names (clean_names() added "x"s)
    pivot_longer(cols = -c(country, commodity, trade, unit),
                   names_to = "year", values_to = "value") %>% 
  mutate(year = as.numeric(year))
# view pivoted table
singapore_orn_new_pivot %>% filter(year %in% c(2017:2022)) %>%  arrange(desc(year))
# all 0s for all years...

# prep for joining
singapore_quant_new <- singapore_orn_new_pivot %>% 
  filter(year %in% c(2017:2022)) %>%  
  arrange(desc(year)) %>% 
  rename(new_quantity = value)


# check old quantity data ----
f_old <- files_old[1]
units <- c("tonnes", "usd")[str_detect(f_old, c("quant", "value"))]

d_old <- readr::read_csv(f_old)

# filter, clean, tidy old quantity data
singapore_old_raw <- d_old %>% 
  janitor::clean_names() %>% 
  filter(reporting_country_name %in% c("Singapore"),
         trade_flow_name %in% c("Exports")) %>% 
  dplyr::select(-c(unit_name)) %>% # "Tonnes – net product weight" == TPW
    rename(country = reporting_country_name,
           commodity = commodity_name,
           trade = trade_flow_name) 

# filter to ornamentals
singapore_ornamental_old_raw <- singapore_old_raw %>% 
  filter(str_detect(commodity, pattern = "Ornamental saltwater fish"))

# pivot year columns
singapore_orn_old_pivot <- singapore_ornamental_old_raw %>% 
   rename_with(~ gsub("x", "", .)) %>% # tidy up year column names (clean_names() added "x"s)
    pivot_longer(cols = -c(country, commodity, trade, unit),
                   names_to = "year", values_to = "value") %>% 
  mutate(year = as.numeric(year))
# view pivoted table
singapore_orn_old_pivot %>% filter(year %in% c(2017:2022)) %>%  arrange(desc(year))

# also all 0s for all years...

# prep for joining
singapore_quant_old <- singapore_orn_old_pivot %>% 
  filter(year %in% c(2017:2022)) %>%  
  arrange(desc(year)) %>% 
  rename(old_quantity = value)


# join to compare 
singapore_quant_comp <- full_join(singapore_quant_new, singapore_quant_old, 
                                  by = join_by(country, commodity, trade, unit, year))

singapore_quant_comp

```

data is consistent across the two years' data... consistent 0s

---
Figured this out after running all of the code after this :,,,)

- I might have figured something out...

in `fao_fxn.R`, line 54 shows:

value = ifelse(value == '...', NA, value), # FAO's code for NA

this basically won't work on our "0 ..." cases... we need to use str_detect(value, "...") instead...?


also possible that they had selected more or fewer numbers after the decimal point compared to the modern default current: (max = 2 after, min = 1 before...)
---

```{r}
sing_pattern_check <- singapore_orn_new_pivot %>% 
  filter(year %in% c(2017:2022)) %>% 
  filter(str_detect(value, pattern = "..."))

sing_pattern_check
# this works, while the "== '...'" would not!


singapore_quant_comp %>% 
  filter(str_detect(new_quantity, pattern = "..."),
         str_detect(old_quantity, pattern = "..."))

singapore_quant_comp %>% 
  filter(old_quantity == "..." # worked before since they didn't also have "0" 
         )

singapore_quant_comp %>% 
  filter(new_quantity == "...") # doesn't work!!
```


```{r}
singapore_orn_new_pivot %>% 
  filter(year %in% c(2017:2022)) %>% 
  arrange(desc(year))

test_sing_cond <- singapore_orn_new_pivot %>% 
  filter(year %in% c(2017:2022)) %>% 
  mutate(value = case_when(
    str_detect(value, "0  ...") ~ NA,
    TRUE ~ value
    )) %>% 
  arrange(desc(year))

test_sing_cond


singapore_orn_new_pivot %>% 
  filter(year %in% c(2017:2022)) %>%
  fao_clean_data_new() %>% 
  arrange(desc(year))
```



```{r check-value-data}
# select value file from list of quant, value
f_value <- files[2]
f_value_old <- files_old[2]

# read in new and old value data
d_value <- readr::read_csv(f_value)
d_value_old <- readr::read_csv(f_value_old)

# ---- prep and filter new data ----
# basic tidying and filtering
singapore_value_raw <- d_value %>% 
  janitor::clean_names() %>% 
  filter(reporting_country_name %in% c("Singapore"),
         trade_flow_name %in% c("Exports")) %>% 
  dplyr::select(-c(unit_name)) %>% # "Tonnes – net product weight" == TPW
    rename(country = reporting_country_name,
           commodity = commodity_name,
           trade = trade_flow_name) 

# filter to ornamental saltwater fish
singapore_ornamental_value <- singapore_value_raw %>% 
  filter(str_detect(commodity, pattern = "Ornamental saltwater fish"))
# 0s until 2010, then values through 2022. 2022 value is 88 (down from 208 in 2021)

# pivot years -
sing_orn_value_pivot <- singapore_ornamental_value %>% 
  rename_with(~ gsub("x", "", .)) %>% # tidy up year column names (clean_names() added "x"s)
    pivot_longer(cols = -c(country, commodity, trade, unit),
                   names_to = "year", values_to = "value") %>% 
  mutate(year = as.numeric(year))



# define year range ----
max_year <- max(sing_orn_value_pivot$year)
start_year <- max_year - 5 # not 4 bc we want to include the 5-year range for the previous year's data as well to get a better understanding of how the 5yr rolling avg has changed
year_range <- seq(start_year, max_year)
year_range # 2017 to 2022

# filter to relevant year range
singapore_orn_value_new <- sing_orn_value_pivot %>% 
  filter(year %in% year_range) %>% 
  arrange(desc(year))



# ---- repeat steps for last year's data  ----
# basic tidying and filtering
singapore_value_old_raw <- d_value_old %>% 
  janitor::clean_names() %>% 
  filter(reporting_country_name %in% c("Singapore"),
         trade_flow_name %in% c("Exports")) %>% 
  dplyr::select(-c(unit_name)) %>% # "Tonnes – net product weight" == TPW
    rename(country = reporting_country_name,
           commodity = commodity_name,
           trade = trade_flow_name) 

# filter to ornamental saltwater fish
singapore_ornamental_value_old <- singapore_value_old_raw %>% 
  filter(str_detect(commodity, pattern = "Ornamental saltwater fish"))
# 0s until 2010, then values through 2022. 2022 value is 88 (down from 208 in 2021)

# pivot years
sing_orn_value_pivot_old <- singapore_ornamental_value_old %>% 
  rename_with(~ gsub("x", "", .)) %>% # tidy up year column names (clean_names() added "x"s)
    pivot_longer(cols = -c(country, commodity, trade, unit),
                   names_to = "year", values_to = "value") %>% 
  mutate(year = as.numeric(year))

# filter to relevant year range
singapore_orn_value_old <- sing_orn_value_pivot_old %>% 
  filter(year %in% year_range) %>% 
  arrange(desc(year))

# look at relevant data ----
singapore_orn_value_new <- singapore_orn_value_new %>% rename(new_value = value)
singapore_orn_value_old <- singapore_orn_value_old %>% rename(old_value = value)


sing_orn_value_comp <- full_join(singapore_orn_value_new, singapore_orn_value_old, by = join_by(country, commodity, trade, unit, year))

sing_orn_value_comp
```
data is consistent across years between the two years' datasets

notable -- 2018 values are not 0... why are they near 0 in the np_tonnes object created in step 2?

so... why do we see such a discrepancy in how gapfilling etc. worked to result in the final quantity column? 


```{r}
sing_orn_value_pivot %>% arrange(desc(year))
#sing_orn_value_pivot %>% fao_clean_data_new() %>% arrange(desc(year))

sing_orn_value_pivot %>% 
#filter(year %in% c(2017:2022)) %>% 
  mutate(value = case_when(
    str_detect(value, "0  ...") ~ NA,
    TRUE ~ value
    )) %>% 
  arrange(desc(year))


singapore_orn_new_pivot %>% mutate(value = case_when(
    str_detect(value, "0  ...") ~ NA,
    TRUE ~ value
    )) %>% arrange(desc(year))


sing_orn_value_pivot %>% fao_clean_data_new()  %>% arrange(desc(year))

```




---

Reran STEP1a_np_ornamentals_prep.Rmd with updated `fao_fxn.R`, seems that 2017 and 2018 values for tonnes were properly replaced with NAs!

```{r}
# Read in quant dataset from intermediate folder
h_tonnes <- read_csv(here(current_np_dir, "int", "tonnes.csv"))

# Read in value dataset from intermediate folder
h_usd <- read_csv(here(current_np_dir, "int", "usd.csv"))

h_tonnes %>% filter(rgn_name == "Singapore", year %in% c(2017:2022), commodity == "Ornamental saltwater fish")
```


more gapfilling check:

```{r}
## h includes rgn_name, rgn_id, commodity, product, year, tonnes, usd.
h <- h_usd %>%
    full_join(h_tonnes, by = c('rgn_name', 'rgn_id', 'commodity', 'product', 'year')) %>%
    mutate(commodity = as.character(commodity)) %>%
    arrange(rgn_id, product, commodity, year) 

# clip out years prior to first reporting year, for each commodity per region
h <- h %>% np_harvest_preclip()


# save a file to use in our methods document 
readr::write_csv(h, here(current_np_dir, "int", "h_methods_sum.csv"))

# test <- h %>%
#   group_by(product) %>%
#   summarise(sum_tonnes = sum(tonnes, na.rm = TRUE),
#             sum_usd = sum(usd, na.rm = TRUE)) ## we will show this table in the methods doc

# ---- filter for our commodities of interest ----
h <- h %>%
    dplyr::filter(product %in% c("fish_oil", "ornamentals", "seaweeds")) 


# gapfilling ----

h <- h %>% np_harvest_gapflag()
## Adds flag for required gap-filling, based upon NAs in data. 
## NOTE: Does not perform any gap-filling.
## At this point, h includes: 
##    rgn_name   rgn_id   commodity   product   year   tonnes   usd   gapfill
## 'gapfill' will be in (zerofill, endfill, tbd, none)

sing_gfill_flags <- h %>% filter(rgn_name == "Singapore", 
                         year %in% c(2017:2022)) %>% 
  arrange(desc(year))
sing_gfill_flags
# so many are marked with tbd


data_check <- h %>% np_datacheck()
## for each commodity within each region, creates (but doesn't save...) summary info:
##   num_years:        the length of the data series for this commodity in this region
##   usd_unique_nz:    (or 'tns') number of unique non-zero values for usd or tonnes 
##   usd_na & tns_na:  number of NA occurrences
##   paired_obs:       number of non-zero paired observations
##   usd_unique_pairs: (or 'tns') within set of paired observations, count of unique usd and tonnes
##   unique_pairs:     lesser of usd_unique_pairs and tns_unique_pairs
##   count_no_data:    number of paired NAs - years with no value reported

h_zerofill <- h %>% np_zerofill()
## for post-reporting years with NA for both tonnes and USD, fill zero - 
##    assumes that non-reporting indicates zero harvest to report.
## Also cross-fills zeros where one side is 0, other is NA (not flagged as gapfill)

h_lowdata_filter <- h_zerofill %>% np_lowdata_filter()
## Exclude commodities (within a region) that have few non-zero data points.
## Optional parameter with default: nonzero_h_yr_min = 4
## NOTE: This filter has consequences for the regression, but also has meaning in terms of 
##    not inflicting a penalty on regions trying, and then stopping, an experimental harvest.

## Melanie's script to add a georegional ID tag based on country keys and IDs.
h_georegion_id <- h_lowdata_filter %>%
  add_georegion_id()

h_regr_fill_1 <- h_georegion_id %>% np_regr_fill(years_back = 10, vars = 'td', scope = 'rgn_id')

# check singapore
h_regr_fill_1 %>% filter(rgn_name == "Singapore", 
                         year %in% c(2017:2022)) %>% 
  arrange(desc(year))

# so many are marked with tbd

h <- h %>% np_regr_fill(vars = 'tdy', scope = 'georgn_id')
h <- h %>% np_regr_fill(vars = 'tdy', scope = 'global')
## np_regr_fill() is a generalized regression gapfill function. Parameters (with defaults):
## * years_back=50 (int):     This determines how far back in the time series to include within the regression.
## * min_paired_obs=4 (int):  This determines how many paired observations are required to attempt a regression.
## * scope = 'rgn_id' (str):  ('rgn_id', 'georgn_id', 'global') Determines grouping scale for regression.
## * vars = 'tdy' (str):      ('td', 'tdy') Determines model: (tonnes ~ usd) or (tonnes ~ usd + year) [and vice versa]

h <- h %>% np_end_fill()
## For final year of data, if both usd and tonnes originally reported as NA, pull forward
##    values for usd and tonnes from the previous year.  This should happen after regression fill.

h_comm <- h
## Store commodity-level data, before moving on to the product-level smoothing.

## Output gapfilling report to .csv files.
## Very few usd gapfilling, and none in recent years (data used to weight contributions), so will ignore this: gapfill=="r2_u_gr"
h_gap <- h %>%
  mutate(gapfill = ifelse(gapfill == "r2_u_gr", "none", gapfill)) %>%   # focusing only on tonnes gapfilling
  dplyr::select(rgn_id, commodity, product, year, gapfill)

h_gap_ornamentals <- h_gap %>%
  filter(product == "ornamentals")
```


---

```{r}
# commodity table

com2prod <- readr::read_csv(here::here(current_np_dir, "raw", "commodities2products_weighting.csv"), na = '')

```




```{r}
# ---- Preliminary cleaning & tidying ----
  ## gather into long format and clean up FAO-specific data foibles
  ## warning: attributes are not identical across measure variables; they will be dropped: this is fine (didn't get this warning in v2024 once code was updated)
  m <- d %>% 
    janitor::clean_names() %>% 
    dplyr::select(-c(unit_name)) %>% # "Tonnes – net product weight" == TPW
    rename(country = reporting_country_name,
           commodity = commodity_name,
           trade = trade_flow_name) %>%
    rename_with(~ gsub("x", "", .)) %>% # tidy up year column names (clean_names() added "x"s)
    pivot_longer(cols = -c(country, commodity, trade, unit),
                   names_to = "year", values_to = "value") 
  
  # ---- Include only the "Exports" data ----
  m <- m %>%
    filter(trade == "Exports")

  # ---- Run fao data cleaning function ----
  # cleans up flags, swaps out FAO-specific codes for analysis
  m <- m %>%
    fao_clean_data_new() %>%  # swaps out FAO-specific codes. NOTE: optional 
    # parameter 'sub_N' can be passed to control how an 'N' code is interpreted.
    dplyr::select(-c(trade, unit)) %>% # drop 'trade' and 'unit' columns
    arrange(country, commodity, is.na(value), year)
  # warning: NAs introduced by coercion

  
  # ---- Products join ----
  ## attach product categories from com2prod, and filter out all entries that 
  ## do not match a product category.
  ## Note: commodity_lookup is user-defined function to compare commodities
  ##  in data vs commodities in lookup table
  
  # Load lookup for converting commodities to products
  #com2prod <- read.csv(here::here(current_np_dir, "raw", "commodities2products_weighting.csv"), na.strings = '')
  com2prod <- readr::read_csv(here::here(current_np_dir, "raw", "commodities2products_weighting.csv"), na = '')
  
  ## version used in 2019:
  ##    read.csv(here('globalprep/np/v2019/raw/commodities2products.csv'), na.strings='')
  ## version used in 2018:
  ##    com2prod <- read.csv('raw/commodities2products.csv', na.strings='')
  ## version used in 2015: use when testing....
  ##    com2prod <- read.csv('../v2014_test/commodities2products.csv', na.strings='')
    
  ## Check the current commodity-to-product lookup table.  If necessary, make changes to     "raw/commodities2products_weighting.csv"
  ## v2021: Missing a couple in each category. 
  # Make sure to examine the fish oil category thoroughly though. Some of the instances that are caught here are NOT fish oil. For example: "Whole lobsters Homarus spp,  in shell or not, dried, salted/in brine, smoked,  cooked by steaming/boiling in water" is including because "boiling" has "oil" in it. Add the appropriate missing commodities to commodities2products_weighting.csv
  # Don't worry about any that show up under corals, shells, or sponges, since we don't include them in the assessment anyways. We are just keeping them in for now, because we use them as an example in the methods document (see below).
  np_commodity_lookup(m, com2prod) 
    
  ## inner_join will attach product names to matching commodities according to
  ##    lookup table 'com2prod', and eliminate all commodities that do not appear in the lookup table.
  m <- m %>%
      inner_join(com2prod, by = 'commodity')
  # many-to-many relationship is expected
    
    
  ## Special case: user-defined function deals with 
  ##   breaking up Antilles into separate reported rgns
  m <- ohicore::split_regions(m)
    
  ## Some changes to region names that aren't working in name_2_rgn()
  m <- m  %>%
    filter(country != "Azerbaijan") 

  m_rgn <- ohicore::name_2_rgn(df_in = m,
                      fld_name = 'country', 
                      flds_unique = c('commodity', 'product', 'year'))
  
  # check duplicates
  # m_duplicates <- m_rgn[duplicated(m_rgn[, c("rgn_name", "year", "commodity", "product")]),]
  # unique(m_duplicates$country)
  # unique(m_duplicates$rgn_name)

  
  # v2024 removed: 
  # Ascension, Saint Helena and Tristan da Cunha -- new syntax from previous years, will update ohicore::split_regions() to account for this change
  # Yugoslavia SFR  -- this is fine, since it broke up into the six modern countries: Croatia, Montenegro, Serbia, Slovenia, Bosnia and Herzegovina, and Macedonia in 1990-1992, which means the relevant data is still captured.
  
  # v2021 duplicates:  [1] "China" "China, Hong Kong SAR" "China, Macao SAR"  "Guadeloupe"           
  # [5] "Martinique" "Montenegro"  "Russian Federation" "Serbia and Montenegro"
  # [9] "Sudan" "Sudan (former)" "Un. Sov. Soc. Rep."   - these are all fixed in the group by and summarise below  
  
  # v2024 duplicates for quantity and value: 
  # [1] "China, Hong Kong SAR"  "China, Macao SAR"      "Martinique"    
  # [4] "Serbia and Montenegro" "Sudan (former)"        "Un. Sov. Soc. Rep." 
  
  ## combine composite regions
  ## When summarizing the dataset, this function provides a modified way to sum the value column while maintaining NA values when both variables are NA (rather than turning to zero values). The function will sum non-NA values normally.
  sum_function <- function(x) {
    if (sum(is.na(x)) == length(x)) 
      return(NA)
    return(sum(x, na.rm = T))}
  
  m_rgn <- m_rgn %>%
    group_by(rgn_id, rgn_name, commodity, product, year) %>%
    summarize(value = sum_function(value)) %>%
    ungroup()

  ## units: rename value field to units based on filename
  names(m_rgn)[names(m_rgn) == 'value'] <- units  
  
   ## output to .csv - should create two csvs (tonnes.csv and usd.csv)
  harvest_out <- here::here(current_np_dir, "int", sprintf("%s.csv", units))
    #(paste0('globalprep/np/v', scen_year, '/int/%s.csv')), units)
  readr::write_csv(m_rgn, harvest_out, na = '')
```






```{r}
# Read in quant dataset from intermediate folder
h_tonnes <- read_csv(here(current_np_dir, "int", "tonnes.csv"))

# Read in value dataset from intermediate folder
h_usd <- read_csv(here(current_np_dir, "int", "usd.csv"))

# concatenate h_tonnes and h_usd data
## h includes rgn_name, rgn_id, commodity, product, year, tonnes, usd.
h <- h_usd %>%
    full_join(h_tonnes, by = c('rgn_name', 'rgn_id', 'commodity', 'product', 'year')) %>%
    mutate(commodity = as.character(commodity)) %>%
    arrange(rgn_id, product, commodity, year) 

# clip out years prior to first reporting year, for each commodity per region
h <- h %>% np_harvest_preclip()


# save a file to use in our methods document 
readr::write_csv(h, here(current_np_dir, "int", "h_methods_sum.csv"))

# test <- h %>%
#   group_by(product) %>%
#   summarise(sum_tonnes = sum(tonnes, na.rm = TRUE),
#             sum_usd = sum(usd, na.rm = TRUE)) ## we will show this table in the methods doc

# ---- filter for our commodities of interest ----
h <- h %>%
    dplyr::filter(product %in% c("fish_oil", "ornamentals", "seaweeds")) 
```



```{r}
h <- h %>% np_harvest_gapflag()
## Adds flag for required gap-filling, based upon NAs in data. 
## NOTE: Does not perform any gap-filling.
## At this point, h includes: 
##    rgn_name   rgn_id   commodity   product   year   tonnes   usd   gapfill
## 'gapfill' will be in (zerofill, endfill, tbd, none)

data_check <- h %>% np_datacheck()
## for each commodity within each region, creates (but doesn't save...) summary info:
##   num_years:        the length of the data series for this commodity in this region
##   usd_unique_nz:    (or 'tns') number of unique non-zero values for usd or tonnes 
##   usd_na & tns_na:  number of NA occurrences
##   paired_obs:       number of non-zero paired observations
##   usd_unique_pairs: (or 'tns') within set of paired observations, count of unique usd and tonnes
##   unique_pairs:     lesser of usd_unique_pairs and tns_unique_pairs
##   count_no_data:    number of paired NAs - years with no value reported

h <- h %>% np_zerofill()
## for post-reporting years with NA for both tonnes and USD, fill zero - 
##    assumes that non-reporting indicates zero harvest to report.
## Also cross-fills zeros where one side is 0, other is NA (not flagged as gapfill)

h <- h %>% np_lowdata_filter()
## Exclude commodities (within a region) that have few non-zero data points.
## Optional parameter with default: nonzero_h_yr_min = 4
## NOTE: This filter has consequences for the regression, but also has meaning in terms of 
##    not inflicting a penalty on regions trying, and then stopping, an experimental harvest.

## Melanie's script to add a georegional ID tag based on country keys and IDs.
h <- h %>%
  add_georegion_id()

h <- h %>% np_regr_fill(years_back = 10, vars = 'td', scope = 'rgn_id')
h <- h %>% np_regr_fill(vars = 'tdy', scope = 'georgn_id')
h <- h %>% np_regr_fill(vars = 'tdy', scope = 'global')
## np_regr_fill() is a generalized regression gapfill function. Parameters (with defaults):
## * years_back=50 (int):     This determines how far back in the time series to include within the regression.
## * min_paired_obs=4 (int):  This determines how many paired observations are required to attempt a regression.
## * scope = 'rgn_id' (str):  ('rgn_id', 'georgn_id', 'global') Determines grouping scale for regression.
## * vars = 'tdy' (str):      ('td', 'tdy') Determines model: (tonnes ~ usd) or (tonnes ~ usd + year) [and vice versa]

h <- h %>% np_end_fill()
## For final year of data, if both usd and tonnes originally reported as NA, pull forward
##    values for usd and tonnes from the previous year.  This should happen after regression fill.

h_comm <- h
## Store commodity-level data, before moving on to the product-level smoothing.

## Output gapfilling report to .csv files.
## Very few usd gapfilling, and none in recent years (data used to weight contributions), so will ignore this: gapfill=="r2_u_gr"
h_gap <- h %>%
  mutate(gapfill = ifelse(gapfill == "r2_u_gr", "none", gapfill)) %>%   # focusing only on tonnes gapfilling
  dplyr::select(rgn_id, commodity, product, year, gapfill)

h_gap_ornamentals <- h_gap %>%
  filter(product == "ornamentals")

```

