---
title: 'Aggregate IUCN spp ranges, range-rarity weighted'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '../../../../workflow/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---



```{r}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
```

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)
library(raster)
library(sf)
library(fasterize)
library(dplyr)
# library(rgdal)
library(here)
library(ggplot2)
# library(rgeos)
library(terra)

source(here('workflow/R/common.R'))

goal     <- 'spp'
scenario <- 'v2024'
dir_goal <- here('globalprep', goal, scenario)

### goal specific folders and info
dir_data  <- file.path(dir_goal, '_data')
dir_setup <- file.path(dir_goal, '_setup')
dir_anx  <- file.path(dir_M, 'git-annex/globalprep')
dir_goal_anx <- file.path(dir_anx, goal, scenario, 'spp_risk_dists')
dir_raw_data_anx <- file.path(dir_anx, '_raw_data')
dir_spatial <- file.path(dir_goal, '_spatial')

source(file.path(dir_setup, 'common_fxns.R'))

dir_bli <- file.path(dir_M, 'git-annex/globalprep/_raw_data/birdlife_intl/d2021')
dir_shp <- file.path(dir_M, 'git-annex/globalprep/_raw_data/iucn_spp/d2024-1')
  ### in this folder are shapefiles at a taxonomic level, both from
  ### IUCN spatial data download (version 2022-1)

```

# Summary

Using individual species range data (csv outputs from `5c_rasterize_spp_shps.Rmd`), collect into species groups.  In each species group, process range and risk information to get mean risk, variance of risk, species richness, and threatened species count per cell.  These are all weighted by species range rarity as a metric of endemism.

# Methods

## Generate species group maps - range-rarity weighting per cell

* Determine species ranges using ocean-area data.frame and cell location data.frame.  Create an overall data.frame and save as .csv.
    * Compare to polygon range areas
* Collect all taxon species into a single data.frame.
* Join species extinction risk and trend data.frame to species-cell data.frame, including regional assessments.
* Join species range area 
* By cell, calculate range-rarity-weighted mean extinction risk, variance of extinction risk, trend, threatened species count, rr_richness, rr_trend_richness (where rr_richness is range-rarity weighted species richness)
    * When aggregating further, use rr_richness to weight values.
    
__NOTE:__ as above, because the summary files are likely to be very large for globe-spanning taxa, save these outputs outside of GitHub.

### Calculate range from the rasterized range maps

This calculated range includes ONLY ocean area. For species such as birds whose range is primarily over land but extends somewhat out over the ocean, this will underpredict range according to the polygons.  For marine species whose range is extremely tiny, the raster may miss the presence of a species entirely.  These ranges will be checked against the polygon areas as a quality check.

``` {r calculate_ranges_from_raster_maps}

spp_range_file <- file.path(dir_data,
                            sprintf('iucn_spp_range_area_%s.csv', api_version))
reload <- FALSE

### load area raster, convert to data frame
area_rast <- rast(file.path(dir_spatial, 'ocean_area_rast.tif'))
area_df <- data.frame(cell_id = 1:(nrow(area_rast)*ncol(area_rast)),
                      area_km2 = terra::values(area_rast)) %>%
  rename(area_km2 = ocean_area_rast)

### load csvs of marine species range maps
spp_maps <- read_csv(file.path(dir_data, 
                               sprintf('spp_marine_maps_%s.csv', api_version)),
                     col_types = 'ddcicccl') 
# %>% dplyr::filter(!shp_iucn_sid %in% c(246014055))

spp_ids <- spp_maps$iucn_sid %>%
  unique() %>%
  sort()

if(reload == FALSE & file.exists(spp_range_file)) {
  cat('dont redo spp already calculated...  remove those from the running')
  spp_range_list_done <- read_csv(spp_range_file, col_types = 'ddcc')
  spp_ids <- spp_ids[!spp_ids %in% spp_range_list_done$iucn_sid]
}

message('Processing ', length(spp_ids), ' species range maps.')

## Note: if the birdlife international data is not updated (and stored in mazu under the name iucn_sid_xxxxxxxxx), this function will not work properly. 

## If the if() statement is not working properly (getting Error: file iucn_sid_x.csv does not exist), see the below chunk for troubleshooting which files are causing issues. 
if(length(spp_ids) > 0) { ### any more spp to calculate?
  system.time({
  spp_range_list <- parallel::mclapply(seq_along(spp_ids), mc.cores = 12,
                                       FUN = function(i) {
    x <- spp_ids[i]
    cat_msg(i, ': Processing species ', x)
    spp_map <- read_csv(file.path(dir_goal_anx, 'spp_rasters',
                                  sprintf('iucn_sid_%s.csv', x)),
                        col_types = 'di')
    
    spp_map_area <- spp_map %>% 
      # filter(presence != 5) %>% ### exclude extinct areas
      inner_join(area_df, by = 'cell_id')
    
    spp_range <- data.frame(iucn_sid = x,
                            range_km2 = sum(spp_map_area$area_km2, na.rm = TRUE))
    # spp_range_list[[i]] <- spp_range
    return(spp_range)
  # }
  }) ### end of mclapply
  }) ### end of system.time

  spp_range_df <- bind_rows(spp_range_list) %>%
    left_join(spp_maps %>% 
                dplyr::select(iucn_sid, sciname, dbf_file) %>%
                distinct(),
              by = 'iucn_sid')
} else {
  spp_range_df <- data.frame() ### return an empty data.frame
}
  
if(reload == FALSE & exists('spp_range_list_done')) {
  ### add new area calcs at the end of the dataframe of spp already done
  spp_range_df <- spp_range_df %>%
    bind_rows(spp_range_list_done)
}

write_csv(spp_range_df, spp_range_file)


```

### Chunk for Troubleshooting and Identifying file issues from Chunk 3 

```{r}
# This function determines which iucn_sids exist in spp_maps (from API) but not in v202X/spp_risk_dists/spp_rasters (from raw data download. It does virtually the same thing as the above function but will store the ID's that don't exist to identify which polygon download they come from (IUCN Red List)
fix_this <- function(spp_nums) { # spp_nums are the spp_ids from the above chunk
  results <- list() # Create empty list
  spp_list <- spp_nums # Define variable
  for(i in seq_along(spp_list)) { # spp_list contains species' "iucn_sid" which is what "x" becomes
    # obtain iucn_sid
    x <- spp_list[i] 
    # Set file path to spp_rasters for above iucn_sid
    spp_file <- file.path(dir_goal_anx, 'spp_rasters',
                         sprintf('iucn_sid_%s.csv', x)) # Create a file for each iucn_sid
    # Check if file exists and attempt to read it if it does
    if(file.exists(spp_file)) {
      spp_map <- read_csv(spp_file, col_types = 'di')
      
      spp_map_area <- spp_map %>% 
        # filter(presence != 5) %>% ### exclude extinct areas
        inner_join(area_df, by='cell_id')
      
      spp_range <- data.frame(iucn_sid = x,
                              range_km2 = sum(spp_map_area$area_km2, na.rm=TRUE))
    } else { # If it doesn't exist, still include it so that we can identify where it should come from
      cat_msg("Iucn_sid:", x, "file does not exist")
      spp_range <- data.frame(iucn_sid = x, 
                              range_km2 = NA)
    }
    # Store output in results list 
    results[[i]] <- spp_range
  }
  return(results)
}

fxn_test_results <- fix_this(spp_ids) # according to the math, 50 items took about 20 seconds to run, wich = 0.4s/file*12240 files = 4896s/60s/m = 81.6m / 60m/h = 1.36 hrs
## Started at 5:59pm
## Finish at 6:48

# Following above chunk and creating a dataframe of the bound list from above
results_df <- bind_rows(fxn_test_results)

# Identify which iucn_sid's files did not exist in current v202X/spp_risk_dists/spp_rasters
results_na <- results_df %>% 
  filter(range_km2 %in% c(NA))

# Define old spp_maps data to see if these iucn_sids are present in previous year 
old_map_info <- read_csv(file.path(dir_data,
  sprintf('spp_marine_maps_%s.csv', "2022-1"))) %>%
  dplyr::select(-presence) %>%
  distinct()

# Filter down old map information to determine the files from which the missing iucn_sids came from (for 2024 these missing iucn_sids came from the birdlife international 2021 which makes sense because we didn't update that data for this assessment).
# For future reference, you can use this dataframe to see which taxa names iucn_sids came from that are not present in your data. If you don't recognize them then you should go back to the IUCN Redlist website and download them, then go back to `5c_rasterize_sppp_shps.Rmd`
file_check_df <- old_map_info %>% 
  filter(iucn_sid %in% results_na$iucn_sid)



# This function was used for for rewriting birdlife international files from v2022 spp_rasters to v2024 spp_rasters. It can be used for future years by utilizing the prev_year variable


prev_year = paste0("v", 2022) # Year that you're referencing spp_rasters for 
vector = results_na$iucn_sid # Vector of iucn_sids that you've identified need to be rewritten from prev_year

rewrite_raster_function <- function(vector, prev_year) {
  files_to_rewrite <- vector
  for(i in seq_along(files_to_rewrite)) {
    x <- files_to_rewrite[i] # obtain iucn_sid
    # Identify file 
    spp_file_in <- file.path(sprintf("/home/shares/ohi/git-annex/globalprep/spp/%s/spp_risk_dists/spp_rasters/iucn_sid_%s.csv", prev_year, x))
    
    if(!file.exists(spp_file_in)) { # Send message if it doesn't exist
      
      cat("Iucn sid", x, "not found in", prev_year, "folder", "\n")
      
    } else { # otherwise read it in and rewrite it to current year directory 
      
      cat("Success! Reading and writing iucn sid:", x, "\n")
    # Read file in 
    spp_file <- read_csv(spp_file_in)
    
    spp_file_out <- file.path(dir_goal_anx, 'spp_rasters',
                         sprintf('iucn_sid_%s.csv', x)) # Create a file for each iucn_sid
    
  write_csv(spp_file, spp_file_out)
    }
  }
}

# Run! 
rewrite_raster_function(vector = vector, prev_year = prev_year)

# Once this is done, you can go back up and rerun the above function
```


### calculate range from polygons

This may *over* predict range for many species whose range is limited by depth,
due to polygon buffering.  This can be used to sanity-check the raster-calculated ranges.

``` {r calculate range from polygons, eval = FALSE}

spp_maps <- read_csv(file.path(dir_data, sprintf('spp_marine_maps_%s.csv', api_version)),
                     col_types = 'ddcicccl') 
# %>% dplyr::filter(!shp_iucn_sid %in% c(246014055))

spp_dbfs <- spp_maps$dbf_file %>%
  unique() 
spp_shps <- spp_dbfs %>%
  str_replace('\\.dbf$', '.shp')

polygon_areas_file <- file.path(dir_setup, 'int/polygon_areas2024-1.csv')

reload <- FALSE
if(!file.exists(polygon_areas_file) | reload) {
  
  #### Use a for loop instead.... mclapply is too intensive for mazu with lots of cores... it fails most of the time. 
  
  poly_range_list <- list()
  for(i in seq_along(spp_shps)){
     x <- spp_shps[i]
                            cat_msg(i, ': Processing ', x)
                            shp <- st_read(x)

                            if('id_no' %in% names(shp)) {
                              shp <- shp %>%
                                rename(iucn_sid = id_no)
                            }

                            if('sisid' %in% names(shp)){
                              shp <- shp %>%
                                rename(iucn_sid = sisid)
                            }

                            shp <- shp %>%
                              filter(iucn_sid %in% spp_maps$iucn_sid)
                                ### NOTE: this will miss subpops
                            ## Checking and attempting to fix invalid geometries
                            if(any(!st_is_valid(shp))) {
                              invalid <- which(!st_is_valid(shp))
                              
                              shp[invalid,] <- st_make_valid(shp[invalid,])
                            }
                            ## If any are still invalid after using st_make_valid, don't use s2 and
                            ## hopefully it will work
                            if(any(!st_is_valid(shp))) {
                              sf_use_s2(FALSE)
                              invalid <- which(!st_is_valid(shp))
                              
                              shp[invalid,] <- st_make_valid(shp[invalid,])
                            }
                            
                            range_df <- data.frame(iucn_sid = shp$iucn_sid,
                                                   poly_range_km2 = st_area(shp)) %>%
                              mutate(poly_range_km2 = as.numeric(poly_range_km2 / 1e6))
                            cat_msg(i, ': Finished ', x)
                            
                      poly_range_list[[length(poly_range_list)+1]] = range_df     
    
  }
  
  
  poly_range_df <- poly_range_list %>%
    setNames(basename(spp_shps)) %>%
    bind_rows(.id = 'shp_file') %>%
    group_by(iucn_sid) %>%
    summarize(poly_range_km2 = round(max(poly_range_km2), 3))

  write_csv(poly_range_df, polygon_areas_file)
}
    
```

### plot raster-calculated ranges vs polygon-calculated ranges

``` {r, eval = FALSE}

range_df <- read_csv(polygon_areas_file, col_types = 'dd') %>%
  full_join(read_csv(spp_range_file, col_types = 'ddcc') %>%
              mutate(shp_file = str_replace(dbf_file, 'dbf', 'shp')), 
            by = 'iucn_sid') %>%
  mutate(birds = str_detect(shp_file, 'bli'))

raster_zeros <- range_df %>% 
  filter(range_km2 %in% c(0))

zeros_ids <- data.frame(iucn_sid = raster_zeros$iucn_sid, poly_range_km2 = raster_zeros$poly_range_km2, rast_range_km2 = raster_zeros$range_km2)

######## Here I left off with adding my polygon range estimates to a dataframe for the species that had '0' ranges when calculated as rasters. I am going to use the polygon range estimates for the raster range estimates and potentially write that out or see how the scores change when it is added versus not added back to the original raster dataframe. Fuck this is honestly a difficult layer to get through

range_compare_scatter <- ggplot(range_df, aes(x = range_km2, y = poly_range_km2)) +
  ggtheme_plot() +
  geom_abline(slope = 1, intercept = 0, color = 'green4') + 
  geom_point(aes(color = birds, label = shp_file, label2 = iucn_sid), alpha = .6)

print(range_compare_scatter)
```

Where dots fall on the line, species ranges by raster and by polygon agree.  Where dots fall above the line, polygon range is larger than raster range - likely due to clipping of land-based ranges, and mostly birds.  Where dots fall below the line, polygon range is smaller than the raster range - in these cases, the polygon range may be a combination of multiple polygons, e.g. subpops or seasonal areas; the code above simply takes the largest polygon per ID as a rough check.

## Aggregate species maps to taxa level

Species cell values for category and trend are multiplied by range rarity before summarizing to mean and variance.  Rather than species counts, the sum of range rarity is calculated for each cell.

Since most of these values will be tiny (since range rarity is generally a tiny number for species with any significant area), we can later multiply these by a scaling factor to get something more in line with more convenient orders of magnitude.

``` {r aggregate species maps to taxa}

### Read in lots of data
spp_maps <- read_csv(file.path(dir_data, sprintf('spp_marine_maps_%s.csv', api_version)),
                     col_types = 'ddcicccl') 
# %>% dplyr::filter(!shp_iucn_sid %in% c(246014055))

spp_risk <- read_csv(file.path(dir_data, sprintf('iucn_risk_current_%s.csv', api_version)),
                     col_types = 'dccicccdc') 
# %>% dplyr::filter(!iucn_sid %in% c(246014055))

spp_risk_rgn <- read_csv(file.path(dir_data, sprintf('iucn_risk_rgn_current_%s.csv', api_version)),
                         col_types = 'dcccdc')

spp_trend <- read_csv(file.path(dir_data, sprintf('iucn_trend_by_spp_%s.csv', api_version)),
                      col_types = 'dc_d_') 
# %>% dplyr::filter(!iucn_sid %in% c(246014055))

### load range info and ocean area info
spp_range <- read_csv(file.path(dir_data,
                                sprintf('iucn_spp_range_area_%s.csv', api_version)),
                      col_types = 'dd__')

# ocean_area_rast <- raster(file.path(dir_spatial, 'ocean_area_rast.tif'))
# cell_area_df <- data.frame(cell_ocean_area = values(ocean_area_rast),
#                            cell_id = 1:length(ocean_area_rast))

### make a dataframe of species risk, trend, regional risk, and species range
spp_risk_trend <- spp_risk %>%
  mutate(iucn_rgn = 'global') %>%
  bind_rows(spp_risk_rgn) %>%
  dplyr::select(iucn_sid, iucn_rgn, cat_score) %>%
  left_join(spp_trend, by = c('iucn_sid', 'iucn_rgn')) %>%
  left_join(spp_range, by = 'iucn_sid')

### raster for cell IDs
rast_cell_ids <- rast(file.path(dir_spatial, 'cell_id_rast.tif'))

### Make a dataframe of cell ID to MEOW for regional assessments... also 
### make a lookup of MEOW to region
meow_rgns_rast <- terra::rast(file.path(dir_spatial, 'meow_rast.tif'))
meow_cells_all <- data.frame(cell_id = terra::values(rast_cell_ids),
                             meow_id = terra::values(meow_rgns_rast)) %>%
  rename(cell_id = 1, meow_id = 2) %>%
  filter(!is.na(meow_id))

meow_to_rgn <- read_csv(file.path(dir_spatial, 'iucn_rgn_to_meow.csv'))


```

## Loop over taxonomic groups

``` {r loop over comp-assessed taxa}

### Make a list of taxonomic groups to loop over:
taxa <- spp_maps %>%
  filter(comp_assessed == TRUE) %>%
  .$dbf_file %>%
  basename() %>% unique() %>%
  str_replace('\\.dbf$', '')

# taxa <- taxa[str_detect(taxa, 'acipenser|bli_marine|TERR|SEAGRASS')] #no acipenser in this... not comp assessed? 

reload <- FALSE

for(taxon in taxa) {
  ### taxon <- 'SEAGRASSES'
  ### taxon <- taxa[10]
  
  taxon_risk_sum_file <- file.path(dir_goal_anx, 'taxa_summaries',
                                   sprintf('%s_cell_sum_comp_rrweight_%s.csv', 
                                           tolower(taxon), api_version))
  
  if(!file.exists(taxon_risk_sum_file) | reload == TRUE) {
    
    taxon_maps <- spp_maps %>%
      filter(str_detect(dbf_file, taxon))
    
    taxon_risk_trend <- spp_risk_trend %>%
      filter(iucn_sid %in% taxon_maps$iucn_sid) %>%
      filter(!is.na(cat_score)) %>%
      arrange(iucn_sid)
    
    ### Using the iucn_sid field, generate a vector of all species range files for
    ### this taxon.
    taxon_ids <- taxon_risk_trend$iucn_sid %>%
      unique()
    
    cat_msg('Processing ', length(taxon_ids), ' species maps in ', basename(taxon), '...')

    ##########################################################.
    ### Looping over species within group -----
    ##########################################################.
    ### Collect all species ranges for this taxon into a single data.frame.
    ### Use mclapply since we're reading many large-ish files.  For MARINE_MAMMALS (85 assessed spp)
    ### this takes about 30-40 seconds
    taxon_cells_list <- parallel::mclapply(taxon_ids, mc.cores = 12,
                                        FUN = function(x) {
       # x <- taxon_ids[1]
        ### x <- 4131                            
        csv_file <- file.path(dir_goal_anx, 'spp_rasters', 
                              sprintf('iucn_sid_%s.csv', x))
        
        spp_risk_map <- read_csv(csv_file, col_types = 'di') %>%
          mutate(iucn_sid = x) %>%
          left_join(taxon_risk_trend, by = 'iucn_sid') 
        
        ### Identify regional assessments if any
        meow_rgns <- meow_to_rgn %>%
          filter(iucn_rgn %in% spp_risk_map$iucn_rgn)
        
        non_global_rgns <- meow_rgns %>%
          filter(iucn_rgn != 'global')
        
        if(nrow(non_global_rgns) > 0) {
          ### If any regional assessments, clip the MEOW cells down to the appropriate region...
          meow_cells <- meow_cells_all %>%
            inner_join(meow_rgns, by = 'meow_id') %>%
            rename(rgn_name = iucn_rgn)
          ### ... then filter out non-matching overlapped cells
          spp_risk_map <- spp_risk_map %>%
            left_join(meow_cells, by = 'cell_id') %>%
            mutate(rgn_name = ifelse(is.na(meow_id), 'global', rgn_name),
                   priority = ifelse(rgn_name == 'global', 100, priority)) %>%
            filter(iucn_rgn == rgn_name) %>%
            group_by(cell_id) %>%
            filter(priority == min(priority)) %>%
            ungroup()
          ### NOTE: at this point, still possible to have multiple regional
          ### assessments, if priorities are the same (e.g. Europe and Pan Africa,
          ### or overlaps around Africa).  Those values will be averaged in
          ### the group_by() below.
        }
        
        ### calc range rarity and select down to main columns; also, 
        ### if presence == 5 (extinct), adjust category and trend scores.
        spp_risk_map <- spp_risk_map %>%
          # left_join(cell_area_df, by = 'cell_id') %>%
          dplyr::select(cell_id, presence, iucn_sid, iucn_rgn, 
                 cat_score, trend_score, range_km2) %>% # , cell_ocean_area) %>%
          distinct() %>%
          mutate(range_rarity = ifelse(range_km2 > 0, 1 / range_km2, 0),
                 cat_score   = ifelse(presence == 5, 1, cat_score),
                 trend_score = ifelse(presence == 5, NA, trend_score)) %>%
          dplyr::select(-range_km2) %>% # , cell_ocean_area) %>%
            ### drop variables no longer needed
          group_by(cell_id, iucn_sid) %>%
          summarize(cat_score   = mean(cat_score, na.rm = TRUE),
                    trend_score = mean(trend_score, na.rm = TRUE),
                    iucn_rgn = paste0(iucn_rgn, collapse = ','),
                    presence = paste0(presence, collapse = ','),
                    range_rarity = first(range_rarity)) %>%
          ungroup() %>%
          mutate(trend_score = ifelse(is.nan(trend_score), NA, trend_score))
        
        return(spp_risk_map)
      }) ### end of mclapply over all species in taxonomic group
  
    ##########################################################.
    ### Processing cell calculations for group -----
    ##########################################################.
  
    ### Set up for keyed data.table merging: key for iucn_sid, cell_id
    cat_msg('...binding rows into data.frame...')
    taxon_risk_map <- bind_rows(taxon_cells_list)
    
    cat_msg('...summarizing...')
    taxon_risk_summary <- taxon_risk_map %>%
      group_by(cell_id) %>%
      summarize(mean_risk = sum(cat_score * range_rarity) / sum(range_rarity), ### NA categories already filtered out
                sr_rr_risk  = sum(range_rarity),
                v1 = sum(range_rarity[!is.na(cat_score)]),   ### for recombining group variances
                v2 = sum(range_rarity[!is.na(cat_score)]^2), ### for recombining group variances
                alpha     = v1 - (v2 / v1), 
                var_risk  = sum(range_rarity * (cat_score - mean_risk)^2) / alpha,
                  ### see https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Weighted_sample_variance
                var_risk  = ifelse(is.nan(var_risk), NA, var_risk),
                  ### for cells with only one spp in the cell, returns NaN, reset to NA
                sr_rr_threatened = sum((cat_score >= 0.4 & cat_score < 1) * range_rarity),  
                mean_trend  = sum(trend_score * range_rarity, na.rm = TRUE) /
                  sum(range_rarity[!is.na(trend_score)]),
                mean_trend  = ifelse(is.nan(mean_trend), NA, mean_trend),
                sr_rr_trend = sum(range_rarity[!is.na(trend_score)]),
                n_spp = n()) %>%
      dplyr::select(-alpha)
    
    cat_msg('...writing file', taxon_risk_sum_file, '...')
    write_csv(taxon_risk_summary, taxon_risk_sum_file)

  } else { ### end of if statement checking whether file exists for this taxon
    cat_msg('Found file ', taxon_risk_sum_file, '... skipping process...')
  }
  
} ### end of taxonomic group loop
  
```

``` {r loop over non-comp-assessed taxa}

### Make a list of taxonomic groups to loop over:
taxa <- spp_maps %>%
  filter(comp_assessed == FALSE) %>%
  .$dbf_file %>%
  basename() %>% unique() %>%
  str_replace('\\.dbf$', '')
# taxa <- taxa[]

for(taxon in taxa) {
  ### taxon <- 'SEAGRASSES'
  # taxon <- taxa[5]
  
  taxon_risk_sum_file <- file.path(dir_goal_anx, 'taxa_summaries',
                                   sprintf('%s_cell_sum_noncomp_rrweight_%s.csv', 
                                           tolower(taxon), api_version))
  
  reload <- FALSE
  if(!file.exists(taxon_risk_sum_file) | reload == TRUE) {
    
    taxon_maps <- spp_maps %>%
      filter(str_detect(dbf_file, taxon)) %>%
      filter(comp_assessed == FALSE) %>%
      filter(max_depth != 'deep oceanic')
    
    taxon_risk_trend <- spp_risk_trend %>%
      filter(iucn_sid %in% taxon_maps$iucn_sid) %>%
      filter(!is.na(cat_score)) %>%
      arrange(iucn_sid)
    
    if(nrow(taxon_risk_trend) == 0) {
      ### if empty set, create a dummy data frame so there
      ### will at least be a file...
      cat_msg('Creating dummy data frame for empty spp set ', taxon)
      taxon_risk_summary <- data.frame(
        cell_id = -1,
        mean_risk = NA)
    } else {
      ### Using the iucn_sid field, generate a vector of all species range files for
      ### this taxon.
      taxon_ids <- taxon_risk_trend$iucn_sid %>%
        unique()
      
      cat_msg('Processing ', length(taxon_ids), ' species maps in ', basename(taxon), '...')
  
      ##########################################################.
      ### Looping over species within group -----
      ##########################################################.
      ### Collect all species ranges for this taxon into a single data.frame.
      ### Use mclapply since we're reading many large-ish files.  For MARINE_MAMMALS (85 assessed spp)
      ### this takes about 30-40 seconds
      taxon_cells_list <- parallel::mclapply(taxon_ids, mc.cores = 24,
                                          FUN = function(x) {
          # x <- taxon_ids[1]
          ### x <- 6336                            
          csv_file <- file.path(dir_goal_anx, 'spp_rasters', 
                                sprintf('iucn_sid_%s.csv', x))
          
          spp_risk_map <- read_csv(csv_file, col_types = 'di') %>%
            mutate(iucn_sid = x) %>%
            left_join(taxon_risk_trend, by = 'iucn_sid') 
          
          ### Identify regional assessments if any
          meow_rgns <- meow_to_rgn %>%
            filter(iucn_rgn %in% spp_risk_map$iucn_rgn)
          
          non_global_rgns <- meow_rgns %>%
            filter(iucn_rgn != 'global')
          
          if(nrow(non_global_rgns) > 0) {
            ### If any regional assessments, clip the MEOW cells down to the appropriate region...
            meow_cells <- meow_cells_all %>%
              inner_join(meow_rgns, by = 'meow_id') %>%
              rename(rgn_name = iucn_rgn)
            ### ... then filter out non-matching overlapped cells
            spp_risk_map <- spp_risk_map %>%
              left_join(meow_cells, by = 'cell_id') %>%
              mutate(rgn_name = ifelse(is.na(meow_id), 'global', rgn_name),
                     priority = ifelse(rgn_name == 'global', 100, priority)) %>%
              filter(iucn_rgn == rgn_name) %>%
              group_by(cell_id) %>%
              filter(priority == min(priority)) %>%
              ungroup()
            ### NOTE: at this point, still possible to have multiple regional
            ### assessments, if priorities are the same (e.g. Europe and Pan Africa,
            ### or overlaps around Africa).  Those values will be averaged in
            ### the group_by() below.
          }
          
          ### calc range rarity and select down to main columns; also, 
          ### if presence == 5 (extinct), adjust category and trend scores.
          spp_risk_map <- spp_risk_map %>%
            # left_join(cell_area_df, by = 'cell_id') %>%
            dplyr::select(cell_id, presence, iucn_sid, iucn_rgn, 
                   cat_score, trend_score, range_km2) %>% # , cell_ocean_area) %>%
            distinct() %>%
            mutate(range_rarity = ifelse(range_km2 > 0, 1 / range_km2, 0),
                   cat_score   = ifelse(presence == 5, 1, cat_score),
                   trend_score = ifelse(presence == 5, NA, trend_score)) %>%
            dplyr::select(-range_km2) %>% # , cell_ocean_area) %>%
              ### drop variables no longer needed
            group_by(cell_id, iucn_sid) %>%
            summarize(cat_score   = mean(cat_score, na.rm = TRUE),
                      trend_score = mean(trend_score, na.rm = TRUE),
                      iucn_rgn = paste0(iucn_rgn, collapse = ','),
                      presence = paste0(presence, collapse = ','),
                      range_rarity = first(range_rarity)) %>%
            ungroup() %>%
            mutate(trend_score = ifelse(is.nan(trend_score), NA, trend_score))
          
          return(spp_risk_map)
        }) ### end of mclapply over all species in taxonomic group
    
      ##########################################################.
      ### Processing cell calculations for group -----
      ##########################################################.
    
      ### Set up for keyed data.table merging: key for iucn_sid, cell_id
      cat_msg('...binding rows into data.frame...')
      taxon_risk_map <- bind_rows(taxon_cells_list)
      
      cat_msg('...summarizing...')
      taxon_risk_summary <- taxon_risk_map %>%
        group_by(cell_id) %>%
        summarize(mean_risk = sum(cat_score * range_rarity) / sum(range_rarity), ### NA categories already filtered out
                  sr_rr_risk  = sum(range_rarity),
                  v1 = sum(range_rarity[!is.na(cat_score)]),   ### for recombining group variances
                  v2 = sum(range_rarity[!is.na(cat_score)]^2), ### for recombining group variances
                  alpha     = v1 - (v2 / v1), 
                  var_risk  = sum(range_rarity * (cat_score - mean_risk)^2) / alpha,
                    ### see https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Weighted_sample_variance
                  var_risk  = ifelse(is.nan(var_risk), NA, var_risk),
                    ### for cells with only one spp in the cell, returns NaN, reset to NA
                  sr_rr_threatened = sum((cat_score >= 0.4 & cat_score < 1) * range_rarity),  
                  mean_trend  = sum(trend_score * range_rarity, na.rm = TRUE) /
                    sum(range_rarity[!is.na(trend_score)]),
                  mean_trend  = ifelse(is.nan(mean_trend), NA, mean_trend),
                  sr_rr_trend = sum(range_rarity[!is.na(trend_score)]),
                  n_spp = n()) %>%
        dplyr::select(-alpha)
    } ### end of empty set check
    
    cat_msg('...writing file', taxon_risk_sum_file, '...')
    write_csv(taxon_risk_summary, taxon_risk_sum_file)

  } else { ### end of if statement checking whether file exists for this taxon
    cat_msg('Found file ', taxon_risk_sum_file, '... skipping process...')
  }
  
} ### end of taxonomic group loop
  
```
