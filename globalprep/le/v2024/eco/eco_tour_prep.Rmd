---
title: "OHI `r format(Sys.Date(), '%Y')` - Economies Tourism Dataprep"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '../../../../workflow/templates/ohi_hdr.html'
pdf_document:
  toc: true
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---

------------------------------------------------------------------------


# Economies Dataprep 

## Overview

-   Tourism GDP \% 
    
    -   preliminary cleaning and tidying
    -   filter, run `ohicore::name_2_rgn()` and make appropriate updates and subsets
    -   investigate data gaps
    -   gapfill
    -   exploratory plotting
        
-   WorldBank GDP (constant 2015 US$)
      
    -   clean and tidy data
    -   make subsets as needed
    -   calculate tourism value for subsets
        
-   NBS China Data 
      
    -   clean and tidy data
    -   adjust and standardize value
        
-   Coastal Population
    
    -   clean and tidy data
    -   calculate coastal proportion multiplier
        
-   USA Coastal Tourism
    
    -   clean and tidy data
    -   subtract Great Lakes values from total values
    -   calculate USA true coastal tourism value, adjust to standardized 2015 US$ for joining
        
-   Combine various subsets as appropriate, get full coastal tourism dataset, standardize for exporting to `int` folder. 

        
        


## UNWTO: Tourism direct GDP as a proportion of total GDP 

**Reference**:  World Tourism Organization. (2024). Tourism direct GDP as a proportion of total GDP (indicator 8.9.1). UNWTO. <https://www.unwto.org/tourism-statistics/economic-contribution-SDG>

**Downloaded**: 2024-07-01

**Last updated**: 2024-04-29

**Description**: 
Tourism direct GDP as a proportion of total GDP (%) for 118 regions. Data is aggregated from multiple sources. 

**Download Instructions**: Navigate to the UN Tourism [Economic Contribution and SDG page](https://www.unwto.org/tourism-statistics/economic-contribution-SDG), find the “Tourism direct GDP as a proportion of total GDP (indicator 8.9.1)” section (should be the first section on the page), right-click on the “Download Data” button, copy the link address, and paste the link in a new tab to download the file (most browsers initially blocked the download and flagged it as “Insecure Content”). Upload the file to the appropriate folder on Mazu (UNWTO/dYYYY/, where YYYY = scenario year, e.g., 2024). 

**Time range**: 2008-2022

**Native data resolution**: Country-level, not spatial data.

**Format**: `.xlsx`

**Metadata**: Linked in the “Download Metadata” button below the “Download Data” button: <http://pre-webunwto.s3.eu-west-1.amazonaws.com/s3fs-public/2024-04/Metadata-08-09-01%202_3_april2024_updated.pdf>
-   A big issue with this data set is that it does not have data for
mainland China. Thus, I was instructed to gapfill using another
data source. I found tourism revenue data on the website for the
National Bureau of Statistics for China



## National Data: National Bureau of Statistics of China (NBS): Development of Tourism

Files downloaded: 
   *   Foreign Exchange Earnings from International Tourism(USD million)
   *   Earnings from Domestic Tourism (100 million yuan)

**Reference**:
National Bureau of Statistics of China. (2024). Foreign Exchange Earnings from International Tourism(USD million). NBS. <https://data.stats.gov.cn/english/easyquery.htm?cn=C01> .

National Bureau of Statistics of China. (2024). Earnings from Domestic Tourism (100 million yuan). NBS. <https://data.stats.gov.cn/english/easyquery.htm?cn=C01> .


**Downloaded**: 2024-07-11

**Last updated**: n.d. 2024 assumed.

**Description**: 
Foreign Exchange Earnings from International Tourism(USD million)
“Foreign Exchange Earnings from International Tourism refer to the total expenditure on transportation, sighting, accommodation, food, shopping and entertainment of foreigners and overseas Chinese during their stay in the mainland of China.” Assumed to be in present USD (i.e., 2018 values are in 2018 USD, 2022 values are in 2022 USD). 

Earnings from Domestic Tourism (100 million yuan)
Earnings from Domestic Tourism in present 100 million yuan. 

**Download Instructions**:
-   Made an account to download data. Feel free to use this same information or create a new account.
-   Email: [aramji\@bren.ucsb.edu](mailto:aramji@bren.ucsb.edu){.email}
-   Password: OHI.f3ll0ws!
-   Security Question: who has influenced you the most? Answer: Melanie Frazier
    *   note: this account may have expired by the next scenario year
-   Return to the [home page](https://data.stats.gov.cn/english/index.htm), click “Annual” from the top navigation bar, then click “Tourism” from options on the left navigation menu, click “Year” dropdown menu and selected “LATEST20”, then clicked the download button and select “.csv”. File appears as “Annual.csv” -- rename this to `eco_tour_china_all_metrics_[start-year]-[end-year].csv`, e.g.,  `eco_tour_china_all_metrics_2004-2023.csv` 
-   Add new file to `_raw_data/NBS_China/dYYYY` folder on Mazu. Replace YYYY with scenario year, e.g., 2024. 

**Time range**: 2004-2023

**Native data resolution**: N/A

**Format**: `.csv`

**Metadata**: <https://data.stats.gov.cn/english/staticreq.htm?m=aboutctryinfo#:~:text=National%20statistical%20indicators%20involved%20in,area%2C%20forest%20resources%20and%20precipitation.>

-   For this tourism revenue data used for China, I wanted to discern whether or not these numbers included Macao and Hong Kong, as that can sometimes be the case (and would significantly impact my data processing methods). Thankfully, the website where I downloaded the data had information on this: 

> "National statistical indicators involved in the database don't contain data from Hong Kong Special Administrative Regions (SAR), Macao SAR and Taiwan Province except for administrative divisions, land area, forest resources and precipitation. Hong Kong SAR and Macao SAR are a part of the overall national statistics. According to the relevant principles of the PRC Hong Kong Basic Law and Macao SAR Basic Law, Hong Kong, Macao and the mainland are relatively independent statistical regions. Based on their different statistical systems and legal requirements, they conduct statistical work independently." <https://data.stats.gov.cn/english/staticreq.htm?m=aboutctryinfo#:~:text=National%20statistical%20indicators%20involved%20in,area%2C%20forest%20resources%20and%20precipitation.> 

-    while this is a little ambiguous, I think it's safe to interpret this to mean that the tourism data we downloaded from the site does not include data from/about Macao and Hong Kong



## World Bank: GDP (constant 2015 US$) 

**Reference**: World Bank. (n.d.). *GDP (constant 2015 US$)*. World Bank Open Data. <https://data.worldbank.org/indicator/NY.GDP.MKTP.KD> .

License: CC BY-4.0

**Downloaded**: 2024-07-09

**Last updated**: No precise date listed on website. Found in the first few pages of the .csv when opened locally: 2024-06-28. 

**Description**: “GDP at purchaser's prices is the sum of gross value added by all resident producers in the economy plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in constant 2015 prices, expressed in U.S. dollars. Dollar figures for GDP are converted from domestic currencies using 2015 official exchange rates. For a few countries where the official exchange rate does not reflect the rate effectively applied to actual foreign exchange transactions, an alternative conversion factor is used.” Aggregation method: Gap-filled total. 

**Download Instructions**: Navigate to the World Bank GDP (constant 2015 US$) data page <https://data.worldbank.org/indicator/NY.GDP.MKTP.KD>. The full time range should be selected on the slider bar by default. Select “CSV” under the “Download” options on the lower right-hand side of the page. Save in the appropriate folder on Mazu: 
`home/shares/ohi/git-annex/globalprep/_raw_data/WorldBank/dYYYY/WorldBank_global_annual_GDP_2015_constant_USD/WorldBank_global_annual_GDP_2015_constant_USD.csv`

**Time range**: 1960-2023

**Native data resolution**: Country-level (not spatial data). 

**Format**: `.csv.` Note: Data is also available in XML and EXCEL formats. 

**Metadata**: Click on “Details” (in the upper right hand corner of the plot on the main page), scroll to the bottom of the popup page, and select “All Metadata”.
<http://databank.worldbank.org/data/reports.aspx?source=2&type=metadata&series=NY.GDP.MKTP.KD&_gl=1*10r25gl*_gcl_au*MTI5NjExNDc0NS4xNzE2NTY4ODAx> 


## Economics: National Ocean Watch (ENOW); Marine Economies: Industries for States and Coastal US

**Reference**:
Office for Coastal Management, 2024: Time-Series Data on the Ocean and Great Lakes Economy for Counties, States, and the Nation between 2005 and 2021 (Sector Level) from 2008-01-01 to 2019-12-31. NOAA National Centers for Environmental Information, <https://www.fisheries.noaa.gov/inport/item/48033>. Downloaded 2024-07-18.
Reference is tailored to the filtered date range used in this project. Actual date range of data was 2005-2021 as of 2024. 
<https://coast.noaa.gov/digitalcoast/data/> 

**Downloaded**: 2024-07-18

**Last updated**: 2022

**Description**: 
Annual marine sector- and industry-level data at national and state levels for coastal (Great Lakes included) United States. Data is processed in this notebook to filter data to the tourism industry and ultimately calculate coastal (Great Lakes exclusive) tourism GDP. RealGDP variable indicated 2012-adjusted GDP.  

> Abstract: Economics: National Ocean Watch (ENOW) contains annual time-series data for over 400 coastal counties, 30 coastal states, 8 regions, and the nation, derived from the Bureau of Labor Statistics and the Bureau of Economic Analysis. It describes six economic sectors that depend on the oceans and Great Lakes and measures four economic indicators: Establishments, Employment, Wages, and Gross Domestic Product (GDP).

Providers: [Bureau of Economic Analysis](https://coast.noaa.gov/digitalcoast/contributing-partners/bureau-economic-analysis.html), [Bureau of Labor Statistics](https://coast.noaa.gov/digitalcoast/contributing-partners/bureau-labor-statistics.html), [NOAA Office for Coastal Management](https://coast.noaa.gov/digitalcoast/contributing-partners/office-for-coastal-management.html). 

Downloaded from NOAA Office for Coastal Management; Digital Coast website: <https://coast.noaa.gov/digitalcoast/data/>.

**Download Instructions**:
Navigate to the [NOAA Digital Coast Data Catalog](https://coast.noaa.gov/digitalcoast/data/) page, scroll down to “Marine Economies: Industries for States and Coastal US” and click on it. Then click the “Download” button, right click on the “Download” hyperlinked text that pops up, and copy and paste it into a new tab in your browser to download the zip file. It should be called “ENOW_Industries.zip”. Open it (unzip it), and upload the whole folder to the appropriate folder on Mazu. 
`home/shares/ohi/git-annex/globalprep/_raw_data/ENOW/d[YYYY]/` replace [YYYY] with your scenario year, e.g., 2024. 

Note: the metadata linked for this data under “Other Resources” on the page where you download it links to the more general Time-Series Data page, which is not specific to this dataset. <https://www.fisheries.noaa.gov/inport/item/48033> 

**Time range**: 2005-2021. Filtered to 2008-2019

**Native data resolution**: State and national level. Not spatial data. `NA` value code: `-9999`.

**Format**: `.csv`

**Metadata**: <https://www.fisheries.noaa.gov/inport/item/48033> . Note: this metadata is not specific to this exact dataset. 

**Notes**:
Has sector-level data:
-   Includes Ship and Boat Building, Tourism and Recreation, Living Resources, Fish hatcheries and aquaculture, Seafood processing, Seafood markets, Fishing, Marine Construction, Marine Transportation, All Ocean Sectors
-   Has employment, wages, GDP, RealGDP columns (RealGDP = adjusted for inflation -- theoretically to year of most recent update based on the metadata, which would be 2021. However, upon futher investigation, the gdp and real gdp values match in the year 2012, so it seems that RealGDP is GDP adjusted to 2012 USD)
-   Contains -9999 values for data privacy – these values are captured in the totals but not in state-level



## National Aggregates of Geospatial Data Collection (NAGDC): Population, Landscape, And Climate Estimates (PLACE), v3 (1990, 2000, 2010)

Used for Coastal Proximity (within 100km of coast) population data. National Aggregates of Geospatial Data Collection (NAGDC). From Socioeconomic Data and Applications Center (SEDAC), hosted by Center for International Earth Science Information Network (CIESIN) at Columbia University. 

**Reference**:
Center for International Earth Science Information Network - CIESIN - Columbia University. 2012. National Aggregates of Geospatial Data Collection: Population, Landscape, And Climate Estimates, Version 3 (PLACE III). Palisades, New York: NASA Socioeconomic Data and Applications Center (SEDAC). <https://doi.org/10.7927/H4F769GP>. Accessed 22 July 2024.

<https://sedac.ciesin.columbia.edu/data/set/nagdc-population-landscape-climate-estimates-v3/data-download>

**Downloaded**: 2024-07-22

**Last updated**: 2012-07-09

**Description**: 
Abstract: 
“The National Aggregates of Geospatial Data Collection: Population, Landscape, And Climate Estimates, Version 3 (PLACE III) data set contains estimates of national-level aggregations in urban, rural, and total designations of territorial extent and population size by biome, climate zone, coastal proximity zone, elevation zone, and population density zone, for 232 statistical areas (countries and other UN recognized territories). This data set is produced by the Columbia University Center for International Earth Science Information Network (CIESIN).” 
Purpose: 
“To provide tabular data to researchers without GIS capabilities who need data on population and land area by country across a range of physical characteristics. These include measures such as the number of persons living within coastal zones, the percent of a region within specific elevation strata, or the number of persons living within different climate zones.”

2010 Coastal Population values used to create proportional multipliers for tourism GDP to calculate coastal tourism value. 

**Download Instructions**:

Navigate to the SEDAC PLACE v3 [Data Download](https://sedac.ciesin.columbia.edu/data/set/nagdc-population-landscape-climate-estimates-v3/data-download) page. Select “CSV” to download the `.csv`. You may need to make an account to download the data. In 2024, our account information was as follows:

*	Username: ohifellows2024
*	Password: OHIfellows.2024!
After logging in, the zip file `nagdc-population-landscape-and-climate-estimates-v3-csv` should be downloaded automatically. Upload this folder to the appropriate folder on Mazu:
`home/shares/ohi/git-annex/globalprep/_raw_data/SEDAC_CIESIN/d[YYYY]`. Replace [YYYY] with the scenario year, e.g., 2024. 

**Time range**: 1990 (January 1), 2000 (January 1), 2010 (January 1)

**Native data resolution**:  This is a `.csv`, but the **Spatial Domain:** is as follows: 
Bounding Coordinates:
West Bounding Coordinate: -180.000000
East Bounding Coordinate: 180.000000
North Bounding Coordinate: 85.000000
South Bounding Coordinate: -58.000000

**Format**: `.csv` Note: Data is also available in `.xlsm` format.

**Metadata**: Navigate to the “Documentation” tab of the PLACE page: <https://sedac.ciesin.columbia.edu/data/set/nagdc-population-landscape-climate-estimates-v3/docs>. Under “Documentation:”, select “Methods (PDF)”. Note: also available as an RTF. 
<https://sedac.ciesin.columbia.edu/downloads/docs/nagdc/nagdc-population-landscape-climate-estimates-v3.pdf> 

Portal metadata:  <https://sedac.ciesin.columbia.edu/data/set/nagdc-population-landscape-climate-estimates-v3/metadata> 

**Notes**: 
-   This data is not updated. Future years should consider using an updated version of PLACE, such as v4. 


## Methods 

### Setup

```{r}
knitr::opts_chunk$set(eval = FALSE)

# ---- Load packages ----

if (!require(librarian)){
  install.packages("librarian")
  library(librarian)
}
librarian::shelf(
  ohicore, # name_2_rgn
  here,
  countrycode,
  janitor,
  priceR, # for inflation adjustment
  RColorBrewer,
  foreach,
  doParallel, # for using multiple cores
  tidyverse, 
  ggplot2,
  tidyr,
  dplyr,
  readr,
  readxl,
  httr,
  scales,
  plotly,
  zoo # for gapfilling
  
)
# for extra gapfilling (v2024: didn't use this method)
# remotes::install_github("skgrange/threadr") # for na_extrapolate
#library(threadr)


# ---- Source common.R ----
source(here::here("workflow", "R", "common.R"))

# ---- Set scenario year, reproducible file paths ----
current_year <- 2024 # Update this!!

version_year <- paste0("v",current_year)
data_dir_version_year <- paste0("d", current_year)
data_path <- here::here("globalprep", "le", version_year)

# Raw data directory (on Mazu)
raw_data_dir <- here::here(dir_M, "git-annex", "globalprep", "_raw_data")

# UNWTO raw data directory
unwto_dir <- here::here(raw_data_dir, "UNWTO", data_dir_version_year)

# World Bank raw data dir (for GDP data)
wb_dir <- here::here(raw_data_dir, "WorldBank", data_dir_version_year)

# China National Bureau of Statistics (NSB) directory
nbsc_dir <- here::here(raw_data_dir, "NBS_China", data_dir_version_year)

# Economics: National Ocean Watch (ENOW) Data for USA Coastal Tourism
enow_dir <- here::here(raw_data_dir, "ENOW", data_dir_version_year, "ENOW_Industries")

# Output data directory -- for intermediate data products
int_dir <- here::here(data_path, "int")
```


## Read in Data

```{r}
# ===================== Read in Data ==============================

# ---- Tourism revenue data ----
gdp_prop_raw <- readxl::read_xlsx(here::here(unwto_dir,
                                       "Indicator-8_9_1-2022-UN_Tourism_april2024_update.xlsx")) # update this if/when new data is downloaded

# ---- OHI regions data ----
region_names <- readr::read_csv("https://raw.githubusercontent.com/OHI-Science/ohi-global/draft/eez/spatial/regions_list.csv") %>% 
  janitor::clean_names() %>% 
  dplyr::select(-notes)

# ---- World Bank GDP in 2015 Constant USD data ----
wb_gdp_raw <- readr::read_csv(here::here(wb_dir,
                                   "WorldBank_global_annual_GDP_2015_constant_USD",
                                   "WorldBank_global_annual_GDP_2015_constant_USD.csv"),
                              skip = 4) # skip first 4 rows
# date range from 1960 to 2023


# ---- NBS China Data (different units for international and domestic tourism) ----
nbsc_raw <- readr::read_csv(here::here(nbsc_dir,
                                       "eco_tour_china_all_metrics_2004-2023.csv"), # update this if/when new data is downloaded
                            skip = 2) # skip first 2 rows

# ---- ENOW Data for USA Coastal Tourism Gapfilling ----
enow_usa_raw <- readr::read_csv(here::here(enow_dir, "ENOW_Industries_2005_2021.csv"), na = c("-9999"))

```


## Tourism GDP % 

### Data cleaning

Current unit of "total" in dataframe:

- "Tourism direct GDP as a proportion of total GDP (%)" 

```{r}
# ---- preliminary cleaning/tidying ----
gdp_prop_clean <- gdp_prop_raw %>% 
  janitor::clean_names() %>% 
  dplyr::select(c(geo_area_name, year = time_period, gdp_prop_percent = total))

# get number of geo areas in dataset
length(unique(gdp_prop_clean$geo_area_name))
# v2024: 117

# make all geographic areas have the same date range (and fill missing values with NAs)
gdp_prop_yrs <- gdp_prop_clean %>% 
  tidyr::complete(geo_area_name, 
           year = min(year):max(year),
           fill = list(value = NA))

# here we can see that the update has been made:
gdp_prop_yrs[46:60,] # for countries without data in certain years,
# the value column (gdp_prop_percent) is populated with NAs (which is what we want!)
# and all geo areas have the same number of years
```

#### Preliminary plot 1: full dataset
Create preliminary plot of cleaned full dataset (not joined/filtered to OHI regions yet)
```{r}
# ---- preliminary plot ----
# define margins
m <- list(
  l = 80,
  r = 60,
  b = 80,
  t = 80,
  pad = 4
)

# ---- create plotly interactive plot ----
prelim_plot <- plotly::plot_ly(data = gdp_prop_yrs,
                       x = ~year,
                       y = ~gdp_prop_percent,
                       color = ~geo_area_name, 
                       type = "scatter", mode = "lines") %>% 
  # update layout: text, margins
  plotly::layout(title = "Tourism direct GDP as a proportion of total GDP (%) for All Geo Regions",
         margin = m, # set margins
         xaxis = list(title = "Year"),
         yaxis = list(title = "Tourism Contribution to GDP (%)"))

# display plot
prelim_plot

# optional: 
# htmlwidgets::saveWidget(prelim_plot, file = "tourism_gdp_prop_all_data.html")
```
v2024 notes/observations:

-   Macao has an extremely high percent of tourism contributing to their GDP (max of 59.6% in 2023)
-   all geographic areas appear to have a sharp decrease in tourism contribution to GDP in 2020, which is to be expected due to the COVID-19 Pandemic. From 2019 to 2020, Macao saw a fall by more than half, from 52.57% in 2019 to 21.44% in 2020.



### Filter & Run OHI region name function

```{r}
# check that this is the intended stop/cutoff year
stop_year <- 2019 # update this depending on data updates

# ---- Filter ----
# set date range selection (rationale described in the paragraph below the previous plot)
gdp_filter <- gdp_prop_yrs %>% 
  dplyr::filter(year <= stop_year)

# ---- Run name_2_rgn -----
# note: if we don't namespace from ohicore:: here, it'll use 
# the local name_2_rgn function stored/defined in this file:
# ~/ohiprep_v2024/globalprep/cw_trend_trash/v2016/georgn_gapfill.R
gdp_rgn <- ohicore::name_2_rgn(df_in = gdp_filter, 
                      fld_name = "geo_area_name",
                      flds_unique = c("year"))

# sorting through mismatch and aggregation ----

# v2024: note on Northern Mariana Islands and Guam OHI region: we only have data for Guam, not Northern Mariana Islands... this is problematic because in the World Bank GDP dataset, we only have GDP data for both the Northern Mariana Islands and Guam and need to aggregate them to fit into the OHI regions system. For now, we'll drop the Northern Mariana Islands GDP data in the WB GDP processing, but please note that if you get GDP % data for this region later on, you'll need to fix that in the GDP data processing chunk.

# v2024: China: we only have data on Hong Kong and Macao, no mainland China data...
# Mel told us to just drop them... which makes sense in context, but is unfortunate, as Macao had the highest values. I will look for data on mainland China to supplement if possible.

# check duplicates         # v2024: (none)
tour_eco_duplicates <- gdp_rgn[duplicated(gdp_rgn[, c("rgn_name", "year")]),]
unique(tour_eco_duplicates$geo_area_name)
unique(tour_eco_duplicates$rgn_name)

length(unique(gdp_rgn$rgn_name))
# v2024: 93

# ---- Rename Macao and Hong Kong ----
gdp_prop_agg <- gdp_filter %>% 
  dplyr::mutate(geo_area_name = case_when(
    geo_area_name == "China, Macao Special Administrative Region" ~ "Macao SAR, China",
    geo_area_name == "China, Hong Kong Special Administrative Region" ~ "Hong Kong SAR, China",
    .default = geo_area_name
  ))


# ---- Run name_2_rgn again -----
gdp_rgn_agg <- ohicore::name_2_rgn(df_in = gdp_prop_agg, 
                          fld_name = 'geo_area_name',
                          flds_unique = c("year"))

# great! now nothing has been removed... now we need to check the duplicates 
tour_agg_duplicates <- gdp_rgn_agg[duplicated(gdp_rgn_agg[, c("rgn_name", "year")]),]
unique(tour_agg_duplicates$geo_area_name)
unique(tour_agg_duplicates$rgn_name)
# inspect duplicates
# gdp_rgn_agg %>% filter(rgn_name == "China")

# ----- China subsets ----
# exclusively China regions
macao_hk_subset <- gdp_rgn_agg %>% 
  dplyr::filter(rgn_name == "China")


# excluding China regions
# (we'll join them back together later once we have the tourism values for HK, Macao, and China) 
no_mc_hk_subset <- gdp_rgn_agg %>% 
  dplyr::filter(rgn_name != "China")


```


#### Exploratory plot: OHI regions, based on `rgn_name`, excluding China

Create preliminary plot with the newly added `rgn_name` field

```{r}
# ---- updated prelim plot ----
ohi_rgns_prelim_plot <- plot_ly(data = no_mc_hk_subset, x = ~year, y = ~gdp_prop_percent, color = ~geo_area_name, 
                                type = "scatter", mode = "lines") %>% 
  layout(title = "Tourism direct GDP as a proportion of total GDP (%) for OHI Regions",
         xaxis = list(title = "Year"),
         yaxis = list(title = "Tourism Contribution to GDP (%)"))

ohi_rgns_prelim_plot


# htmlwidgets::saveWidget(ohi_rgns_prelim_plot, file = "eco_tour_ohi_rgns_prelim_plot.html")
```

It is notable how much the y-axis scale changes once we drop Macao. I think that the -0.1 value we see for Fiji could be indicative of the country spending money on tourism infrastructure, development, and advertisement but then not getting enough tourism revenue due to Covid, but this is worth investigating further (I couldn't find anything helpful in the metadata, unfortunately).


### Heatmap: investigating data gaps


```{r}
library(ggplot2)

heatmap_df <- gdp_rgn_agg %>% 
  dplyr::mutate(status = !is.na(gdp_prop_percent)) %>% 
  dplyr::ungroup()

heatmap_plot <- ggplot(data = heatmap_df) +
  geom_tile(aes(x = year,
                y = geo_area_name,
                fill = as.factor(status)), color = "black") +
  scale_fill_manual(values = c("gainsboro", "darkgreen")) +
  labs(y = "",
       x = "Year",
       title = "Data Status per Region per Year",
       fill = "Does the dataset \n have data for \n this region?:") +
  theme_bw() 

plotly::ggplotly(heatmap_plot)

```



```{r}
# make subset showing counts of data per country

raw_gdp_pct_data_summary <- heatmap_df %>% 
  # group by region name and year
  dplyr::group_by(geo_area_name) %>% 
  # return counts of data points per country pe year (essentially number of years we do have data for)
  dplyr::summarize(n_data_points = sum(status)) %>% 
  dplyr::arrange((n_data_points)) # show number of data points that we have for that region across the full time range 

head(raw_gdp_pct_data_summary, n = 20)

# sum(heatmap_df$status)
```


## Country filtering

Rules:

- Must have at least one data point in the last five years &&
- must have > three data points over time


- After inspecting all of the Economies sector datasets, we decided to set our date range from 2008-2019. There are several reasons for this range:
-  Tourism data starts in 2008
-  Fishing data ends in 2019
-  2020 is rife with statistical anomalies -- this would seriously impact gapfilling (for example, a low 2020 data point may cause extremely inaccurate gapfilling for data missing in 2018-2019)

```{r}
# define date range for filtering
start_year <- 2008
stop_year <- 2019 
date_range <- c(start_year:stop_year) # update this depending on your data!

# create date range of the last 5 years (including most recent year)
recent_years <- c(((max(date_range)) - 4):max(date_range))

# check to see if we need to ungroup
is_grouped_df(heatmap_df)

# ---- at least 1 data point in the last 5 years ----
# filter by number of "TRUE" status
five_yr_subset <- heatmap_df %>% 
  dplyr::filter(year %in% c(recent_years)) %>% 
  dplyr::group_by(geo_area_name) %>% 
  # group_by(rgn_id, rgn_name) %>% 
  dplyr::summarize(n_data_points = sum(status)) %>% 
  dplyr::filter(n_data_points >= 1)
# arrange(n_data_points) # for visual inspection

# extract geo area names
five_yr_geos <- c(five_yr_subset$geo_area_name)

# look at loss from first filtering step:
length(five_yr_geos) # v2024: 89 
length(unique(heatmap_df$geo_area_name)) - length(five_yr_geos) # number of geo areas filtered out
# v2024: 6 
# --- more than 3 data points in time range ----
total_data_points <- heatmap_df %>% 
  # filter to date range
  dplyr::filter(year %in% c(date_range)) %>% 
  # group by geo_area_name
  dplyr::group_by(geo_area_name) %>% 
  # summarize n_data_points
  dplyr::summarize(n_data_points = sum(status)) %>% 
  # filter to > 3
  dplyr::filter(n_data_points > 3)
# extract names

over_three_pts_geos <- c(total_data_points$geo_area_name)  

# look at loss from first filtering step:
length(over_three_pts_geos) # v2024: 77 
length(unique(heatmap_df$geo_area_name)) - length(over_three_pts_geos) # number of geo areas filtered out
# v2024: 18


# ---- filter rgn_names subsets ----
# filter to geo area names in five_yr_subset && total_data_points
# filter(geo_area_name %in% c(five_yr_geos) && geo_area_name %in% c(over_three_pts_geos))

# Subset without Macao and Hong Kong
no_china_filter <- no_mc_hk_subset %>% 
  # filter year for specified date range (double-checking)
  dplyr::filter(year %in% c(date_range)) %>% 
  # filter to geo_area_name that fulfills both (AND) conditions/rules 
  dplyr::filter(geo_area_name %in% c(five_yr_geos) & geo_area_name %in% c(over_three_pts_geos)) %>% 
  # add status column back in for plotting
  dplyr::mutate(status = !is.na(gdp_prop_percent)) %>% 
  dplyr::ungroup()

# Macao & Hong Kong subset
macao_hk_filter <- macao_hk_subset %>% 
  # filter year for specified date range (double-checking)
  dplyr::filter(year %in% c(date_range)) %>% 
  # filter to geo_area_name that fulfills both (AND) conditions/rules 
  dplyr::filter(geo_area_name %in% c(five_yr_geos) & geo_area_name %in% c(over_three_pts_geos)) %>% 
  # add status column back in for plotting
  dplyr::mutate(status = !is.na(gdp_prop_percent)) %>% 
  dplyr::ungroup()
```

#### Heatmap: subset without Macao & Hong Kong

```{r no-mc-hk-heatmap}
# ---- heatmap to check if countries we expected to be removed were removed ----

no_china_heatmap <- ggplot(data = no_china_filter) +
  geom_tile(aes(x = year,
                y = geo_area_name,
                fill = as.factor(status)), color = "black") +
  scale_fill_manual(values = c("gainsboro", "darkgreen")) +
  labs(y = "",
       x = "Year",
       title = "Filtered Data Status per Region per Year (excluding Macao & Hong Kong)",
       fill = "Does the dataset \n have data for \n this region?:") +
  theme_bw() 

plotly::ggplotly(no_china_heatmap)
```

After discussing the datagaps after filtering, Melanie advised that we manually remove Argentina (in v2024, we had 4 total data points for this country, but they were all from the past 4 years (2016-2019)). Note: we also removed the United States in this step, so we're using the ENOW data read in earlier to address this data gap.

```{r}
no_china_filter <- no_china_filter %>% 
  dplyr::filter(!geo_area_name %in% c("Argentina"))
```

#### Heatmap: subset of Macao & Hong Kong

```{r macao-hk-heatmap}
macao_hk_heatmap <- ggplot(data = macao_hk_filter) +
  geom_tile(aes(x = year,
                y = geo_area_name,
                fill = as.factor(status)), color = "black") +
  scale_fill_manual(values = c("gainsboro", "darkgreen")) +
  labs(y = "",
       x = "Year",
       title = "Filtered Data Status per Region per Year (Macao & Hong Kong)",
       fill = "Does the dataset \n have data for \n this region?:") +
  theme_bw() 

plotly::ggplotly(macao_hk_heatmap)
```



### Gapfilling

Here we'll use `na.approx()` from {zoo} to interpolate missing values and extrapolate missing extremes (NA values that do not fall between non-NA values) by copying the nearest extreme value. After speaking with Melanie Frazier about our methodology, she recommended to not fill in any values for countries with only 1 data point (or any that don't satisfy the other rules), which is why we're doing this step after filtering. 

```{r}

# ---- Gapfilling ----
# subset excluding China regions ----
# estimate tourism GDP proportion for geo areas with missing data
no_china_gf <- no_china_filter %>% 
  dplyr::group_by(rgn_id, rgn_name) %>% 
  # interpolate (fill missing values between 2 values)
  dplyr::mutate(appx_gdp_pct = zoo::na.approx(gdp_prop_percent, # using values in this column
                                       na.rm = FALSE, # don't replace (internal) NAs in new column that can't be approximated
                                       #  extrapolate using rule = 2 from approx(),
                                       # which uses closest data extreme to
                                       #  extrapolate for leading and trailing NAs
                                       rule = 2
  )) %>% 
  # rename old status column
  dplyr::rename(raw_status = status) %>% 
  # add gapfilled (GF) status column
  dplyr::mutate(gf_status = !is.na(appx_gdp_pct)) %>% 
  dplyr::ungroup()

# subset with Macao and Hong Kong ----
# estimate tourism GDP proportion for geo areas with missing data
macao_hk_gf <- macao_hk_filter %>% 
  dplyr::group_by(geo_area_name) %>% # not by region name, which would be "China" for both
  # interpolate (fill missing values between 2 values)
  dplyr::mutate(appx_gdp_pct = zoo::na.approx(gdp_prop_percent, # using values in this column
                                       na.rm = FALSE, # don't replace (internal) NAs in new column that can't be approximated
                                       #  extrapolate using rule = 2 from approx(),
                                       # which uses closest data extreme to
                                       #  extrapolate for leading and trailing NAs
                                       rule = 2
  )) %>% 
  # rename old status column
  dplyr::rename(raw_status = status) %>% 
  # add gapfilled (GF) status column
  dplyr::mutate(gf_status = !is.na(appx_gdp_pct)) %>% 
  dplyr::ungroup()
```


```{r}
# subset without OHI China regions ----
no_china_gf_heatmap <- ggplot(data = no_china_gf) +
  geom_tile(aes(x = year,
                y = geo_area_name,
                fill = as.factor(gf_status)), color = "black") +
  scale_fill_manual(values = c("darkgreen", "gainsboro")) +
  labs(y = "",
       x = "Year",
       title = "Filtered & Gapfilled Data Status per Region per Year (excluding Macao & Hong Kong)",
       fill = "Does the dataset \n have data for \n this region?:") +
  theme_bw() 

plotly::ggplotly(no_china_gf_heatmap)
```


Because of all of the filtering that we did earlier, the result of this gapfilling is a completely filled dataset. In previous iterations when we gapfilled before filtering, there were still many NAs (FALSEs) due to large data gaps in the raw dataset.


#### Exploratory plotting: gapfilled GDP % data

```{r}
# ---- create plotly interactive plot ----
prelim_plot_gf <- plot_ly(data = no_china_gf,
                          x = ~year,
                          y = ~appx_gdp_pct,
                          color = ~geo_area_name, 
                          type = "scatter", mode = "lines") %>% 
  # update layout: text, margins
  layout(title = "Tourism direct GDP as a proportion of total GDP (%), Gapfilled \n (Exluding China, Macao & Hong Kong)",
         margin = m, # set margins
         xaxis = list(title = "Year"),
         yaxis = list(title = "Tourism proportion of total GDP (%)"))

# display plot
prelim_plot_gf
```


In future years, when we have more data for 2020 and beyond, or if novel gapfilling techniques are used (e.g., not linear fitting, as the 2019-2020 trend is an irregular pattern poorly suited to linear models), we recommend not cutting off the data after 2019. Studying the impacts of the pandemic on tourism value and the economies subgoal as a whole is important and seems like a very interesting opportunity for future years' fellows.




## GDP: WorldBank annual GDP (Constant 2015 US$)

-  Global dataset of country-level GDP in constant 2015 USD (they write this as US$ in World Bank documentation)

### Data cleaning


```{r}
# use minimum (start) year in tourism GDP % dataset for filtering:
# start_year 2008
# stop_year 2019 
# date_range 2008:2019

# ---- cleaning WorldBank GDP data ----
wb_gdp_clean <- wb_gdp_raw %>% 
  janitor::clean_names() %>% 
  # remove unwanted columns
  dplyr::select(-c(indicator_code, x69)) %>% 
  # pivot to put years in 1 column, values in another
  tidyr::pivot_longer(cols = x1960:x2023, # update if new data downloaded
                      names_to = "year", values_to = "gdp_value") %>% 
  # tidy up year column
  dplyr::mutate(year = as.numeric(str_remove_all(year, 'x'))) %>%  
  # filter to date range
  dplyr::filter(year %in% c(date_range))

```

### Next steps:

-  create subset of GDP data without China, Hong Kong, or Macao: `no_china_gdp`
-  run `name_2_rgn` function on this, make necessary adjustments: `nc_gdp_rgn`, final post-aggreagtion and adjustments: `nc_gdp_rgn_agg`
-  then join with gapfilled, filtered, no-china dataframe `no_china_gf`; call this `no_china_join`
-  calculate usd tourism value for `no_china_join`. call this `nc_tourism_value`

-  create China subset of GDP data `china_gdp`, join with `macao_hk_gf` (gdp proportion subset of Macao and Hong Kong, gapfilled)
-  calculate value (will be in Constant 2015 US$): `macao_hk_value`

## Tourism Value (excluding China)

Now we'll prep to join our GDP and % GDP data frames by first making a subset without China, Macao, or Hong Kong. Then, we'll run `name_2_rgn` from {ohicore} and see what else we need to fix before joining.

```{r nc_rgn_agg}
# ---- make subset excluding China ----
no_china_gdp <- wb_gdp_clean %>% 
  # this works because Macao, Hong Kong, and mainland China all have "China" 
  # in their country_name designations in this dataset
  dplyr::filter(!stringr::str_detect(country_name, "China"))

# check
nrow(no_china_gdp %>% dplyr::filter(stringr::str_detect(country_name, "China")))
# should be 0


# ---- run name_2_rgn ----
# nc = no china
nc_gdp_rgn <- ohicore::name_2_rgn(df_in = no_china_gdp, 
                         fld_name = "country_name",
                         flds_unique = c("year"))

# thankfully, in the list following this line: "These data were removed for not having any match in the lookup tables:", there are mostly just the WorldBank aggregate groups (i.e., "low & middle income, Latin America & Caribbean, etc.), with the exception of Channel Islands (has all NA) and Isle of Man

# don't make the mistake I did, and check your tourism dataset to see if it has Channel Islands, Jersey, or Guernsey first! 
# it doesn't, so we can continue on since the name_2_rgn function helpfully removed this data from the GDP data frame already.

# The Isle of Man is a distinct governing body, and should not be aggregated with Ireland or the UK. It is also not in our tourism dataset, so we can continue on with it being omitted from the df by name_2_rgn. 

# ---- identify duplicates ----
nc_gdp_duplicates <- nc_gdp_rgn[duplicated(nc_gdp_rgn[, c("rgn_name", "year")]),]
#View(wb_gdp_duplicates)
unique(nc_gdp_duplicates$country_name)
unique(nc_gdp_duplicates$rgn_name)


# ---- addressing duplicates ----
# [1] "Northern Mariana Islands and Guam" --> we have GDP data for Northern Mariana Islands, and Guam. Can aggregate this, but we only have tourism % GDP data for Guam (see earlier comment in GDP % data cleaning chunk). 
# For now, we'll just keep Guam GDP and filter out Northern Mariana Islands GDP.


# [2] "Puerto Rico and Virgin Islands of the United States" --> we have data for both in the GDP data frame, but only for Puerto Rico in the GDP % data frame. Thus, we'll need to filter out the US Virgin Islands GDP data and only keep Puerto Rico data to get a more representative value (Puerto Rico tourism proportion of GDP * Puerto Rico GDP, rather than taking the Puerto Rico prop * Puerto Rico + US Virgin Islands GDP)



# ---- aggregate ----
# sum by rgn_name etc.
# name ~ No China GDP region aggregated
nc_gdp_rgn_agg <- nc_gdp_rgn %>%
  dplyr::filter(!country_name %in% c("Northern Mariana Islands", # filtering out NMI since we only have Guam GDP % data in our other dataset -- should revisit this and update once we have that data -- double check to see which of these regions we have data for on both datasets in future years of updates!!!
                                     "Virgin Islands (U.S.)") # similarly, filtering out U.S. Virgin Islands. Only do this if the data continues to have the gaps addressed above.
  ) %>% 
  dplyr::group_by(rgn_id, rgn_name, year) %>%
  dplyr::summarize(gdp_value_agg = sum(gdp_value, na.rm = TRUE)) %>%
  dplyr::ungroup() %>% 
  # turn 0s into NAs (appropriate flag for lack of data, as earlier sum(na.rm = TRUE) step obscured NAs)
  dplyr::mutate(gdp_value_agg = case_when(
    gdp_value_agg == 0 ~ NA, # replace 0 with NA
    .default = gdp_value_agg # maintain all other values
  ))

# ---- aggregation check ----
# to double check and see if Northern Marian Islands was properly filtered out:
agg_nmi_vals <- nc_gdp_rgn_agg %>% 
  dplyr::filter(rgn_name %in% c("Northern Mariana Islands and Guam")) %>%
  dplyr::select(year, gdp_value_agg)

guam_reference <- nc_gdp_rgn %>% 
  dplyr::filter(country_name %in% c("Guam")) %>% 
  dplyr::select(year, gdp_value)

agg_nmi_check <- dplyr::left_join(agg_nmi_vals, guam_reference)

print(paste("Do the Guam GDP values before aggregation match the 'Northern Mariana Islands and Guam' values after aggregation?"))

if (sum(agg_nmi_check$gdp_value_agg == agg_nmi_check$gdp_value) == length(unique(agg_nmi_check$gdp_value_agg))
) {
  print("Yes")
} else {
  print("No")
}

# If "No", check which don't match
# print(paste((agg_nmi_check$gdp_value_agg == agg_nmi_check$gdp_value)))
# use FALSEs for indexing

```



Great! Now we're ready to join with the tourism as a proportion of total GDP subset that excludes China. 
We'll then multiply the percent of GDP by the GDP to yield a value (in constant 2015 USD)

```{r nc_tourism_value}
# ---- join GDP Value (constant 2015 US$) with Tourism GDP % ----
no_china_join <- dplyr::full_join(nc_gdp_rgn_agg, no_china_gf,
                                  by = join_by("rgn_id", "rgn_name", "year"))
# note that because we preserved the `geo_area_name` column, we can see which country is the true representative of the aggregate based on our steps above (e.g., Puerto Rico is the geo_area_name value for the Puerto Rico and US Virgin Islands rgn_name rows)

# that is mostly only useful in the intermediate data processing though, so we will be dropping this column as we move on

# ---- calculate tourism value ----
nc_tourism_value <- no_china_join %>% 
  dplyr::filter(rgn_name != "United States") %>% # drop US (we have separate coastal tourism data for this)
  dplyr::ungroup() %>% 
  dplyr::group_by(rgn_id, rgn_name, year) %>% 
  # get proportion to use as multiplier, multiply by GDP to get value
  dplyr::mutate(tour_value = (appx_gdp_pct / 100) * gdp_value_agg) %>% 
  # fix data types
  dplyr::mutate(rgn_id = as.character(rgn_id)) %>% 
  # select relevant columns for joining
  dplyr::select(c(rgn_id, rgn_name, year, tour_value)) %>% 
  dplyr::ungroup()

#View(nc_tourism_value)
#summary(nc_tourism_value)
```

```{r}
# plot to visually inspect changes
# ---- create plotly interactive plot ----
nc_tourism_plot <- plot_ly(data = nc_tourism_value,
                          x = ~year,
                          y = ~tour_value,
                          color = ~rgn_name, 
                          type = "scatter", mode = "lines") %>% 
  # update layout: text, margins
  layout(title = "Tourism Value in Constant 2015 USD, Gapfilled \n (Exluding United States, China, Macao & Hong Kong)",
         margin = m, # set margins
         xaxis = list(title = "Year"),
         yaxis = list(title = "Tourism Value (2015 USD)"))

# display plot
nc_tourism_plot

```




## Tourism Value: China (including Macao and Hong Kong)

**Overview**

-   create China subset of GDP data: `china_gdp`
    -   filter to only include Hong Kong and Macao: `macao_hk_gdp`
-   join with `macao_hk_gf` (gapfilled, filtered gdp proportion subset with only Macao and Hong Kong): `macao_hk_join`
-   calculate value (will be in Constant 2015 US$): `macao_hk_value`

-   clean & tidy China gapfill dataset from National Bureau of Statistics of China
  -   pivot from wide to long (years columns --> year column), clean again
  -   convert values to standard from GDP dataset -- constant 2015 USD
-   join `china_usd_value` with `macao_hk_value`, drop irrelevant columns etc. and aggregate across `rgn_name` (China): call this `china_value`


### China subset of WB GDP


Remember that China subset we made out of the Macao and Hong Kong data? Now we're going to join that with a subset of the global country-level GDP data to find the tourism value for these areas. We will then join this data frame with the China tourism value data we read in earlier (which we will clean & tidy first) and finally aggregate the values to yield one value per year for China as a region.

```{r china_mo_hk_value}
# ---- filter to China regions GDP ----
china_gdp <- wb_gdp_clean %>% 
  dplyr::filter(stringr::str_detect(country_name, "China")) # depending on the dataset, you'd need to change this to "Macao", "Hong Kong"

# check to see if the names will work with OHI region synonyms
unique(china_gdp$country_name)
# yep! and they're named the same as Hong Kong and Macao are in macao_hk_subset

# Since we already have the Tourism Value for mainland China (which we'll clean and tidy in the chunks below), we'll filter out the GDP rows for China now and then bring the tourism values for China back in at the end before aggregating.

# ----- Prep for joining with Macao + Hong Kong subset ----
# drop "China" rows
macao_hk_gdp <- china_gdp %>% 
  dplyr::filter(country_name != "China") # don't need this, as our China data is already in tourism value format

# check
unique(macao_hk_gdp$country_name)


# ---- Join Macao + HK subsets ----
macao_hk_join <- dplyr::left_join(macao_hk_gf, macao_hk_gdp,
                           by = c("year", "geo_area_name" = "country_name"))


# ---- Calculate tourism value ----
macao_hk_value <- macao_hk_join %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(geo_area_name, year) %>% 
  dplyr::mutate(tour_value = (appx_gdp_pct / 100) * gdp_value) %>% 
  # select relevant columns
  dplyr::select(geo_area_name, year, tour_value)
# remember: the unit of this value is in constant 2015 US$ 
```

Plot to visualize Macao & Hong Kong Tourism Value

```{r}
# ---- Exploratory plot of Macao & Hong Kong tourism value ----
library(scales)
ggplot(data = macao_hk_value, 
       aes(x = as.numeric(year), 
           y = tour_value,
           color = geo_area_name)) +
  geom_point() +
  geom_line() +
  scale_color_viridis_d(begin = 0.0, end = 0.7) +
  scale_x_continuous(breaks = c(date_range)) +
  # make y-axis more legible
  scale_y_continuous(labels = scales::label_currency(scale = 0.000000001,
                                                     suffix = "B",
                                                     # $30.00B --> $30B
                                                     scale_cut = cut_long_scale())) +
  theme_bw() +
  # update labels
  labs(title = paste0("Tourism Value in Hong Kong & Macao ", "(",
                      start_year,
                      "-", stop_year, ")"),
       subtitle = "Data Sources: UNWTO, World Bank",
       x = "Year",
       y = "Tourism Value (Constant 2015 US$)",
       color = "Region") +
  # customize theme elements
  theme(
    axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 0.9),
    axis.title.x = element_text(margin = margin(t = 1.2, b = 0.2, unit = "lines")),
    axis.title.y = element_text(margin = margin(l = 0.5, r = 0.5, unit = "lines")),
    panel.grid.minor.x = element_blank(),
    plot.title = element_text(margin = margin(t = 0.5, b = 0.5, unit = "lines")),
    plot.subtitle = element_text(margin = margin(b = 1, unit = "lines"))
  )
```


### China Tourism Value
Overview: 

-   clean & tidy China Tourism Value dataset 

    -   clean column names
    -   select relevant categories (earnings from international and domestic tourism) and columns (indicators, year columns)
    -   pivot data from wide to long so that `tour(ism)_value` observations are in one column and `year` is in another columns (each row should be 1 observation -- with indicator, year, and earnings)
    -   clean up the new `year` column
    -   filter to date range specified earlier (`start_year` and `stop_year`)

-   convert tourism value (earnings) to a standardized format (we'll go over this in more detail later)
-   prep for joining with China subset (Macao + Hong Kong) of tourism value data 

```{r}
# ---- clean names ----
nbsc_clean <- nbsc_raw %>% 
  janitor::clean_names() 

# get strings for subcategories of tourism data we're looking for (international and domestic tourism earnings)
#unique(nbsc_clean$indicators)
tourism_categories <- c("Foreign Exchange Earnings from International Tourism(USD million)",
                        "Earnings from Domestic Tourism(100 million yuan)")
# here we can see that these values are in different units. 
# We'll want to standardize them to USD, then to Constant 2015 US$ (what the GDP data is in)

# but first, let's tidy up the data! 

# ---- tidy ----
nbsc_tidy <- nbsc_clean %>% 
  dplyr::filter(indicators %in% c(tourism_categories)) %>% 
  tidyr::pivot_longer(cols = x2023:x2004, # update this depending on year range of newly downloaded data
               names_to = "year", values_to = "tour_value") %>% 
  # tidy up year column
  dplyr::mutate(year = as.numeric(str_remove_all(year, 'x'))) %>%  
  # filter to date range defined earlier
  dplyr::filter(year %in% c(date_range))
```

#### Standardize values 

Tried to get the conversion rates in a reproducible way:

- `quantmod::getFX()` documentation: <https://www.rdocumentation.org/packages/quantmod/versions/0.4.26/topics/getFX> -- unfortunately only has rates for the past 180 days (doesn't work for our situation)
- `priceR::historical_exchange_rates()`: requires you to set up an API key -- the free one only gives you 100 requests per month and also requires you to enter credit card information even for the free account...
- documentation/repo for {priceR} : <https://github.com/stevecondylios/priceR?tab=readme-ov-file>


```{r test-conversion-packages, eval=FALSE}
# ---- quantmod ----
# library(quantmod)
# cny_rates_test <- quantmod::getFX("CNY/USD" #, from = paste0(start_year, "-01-01"), to = paste0(stop_year, "-12-31")
#                                   )
# cny_rates_test

# ---- priceR ----
# #tried using the API key posted by the developer
#Sys.setenv("EXCHANGERATEHOST_ACCESS_KEY"="7e5e3140140bd8e4f4650cc41fc772c0")
## get Chinese Yuan to USD conversion rates for time range
# cny_conversion_rate <- priceR::historical_exchange_rates(from = "CNY", to = "USD",
#                           start_date = paste0(start_year, "-01-01"), end_date = paste0(stop_year, "-12-31"))

## returned the following error:
# Error in `pmap()`:
# ℹ In index: 1.
# Caused by error in `dat[[8]]`:
# ! subscript out of bounds
# Backtrace:
#  1. priceR::historical_exchange_rates(...)
#  2. purrr::pmap_dfr(...)
#  3. purrr::pmap(.l, .f, ...)
#  4. purrr:::pmap_("list", .l, .f, ..., .progress = .progress)
#  8. priceR (local) .f(start_date = .l[[1L]][[i]], end_date = .l[[2L]][[i]], ...)
#  9. dat[[8]] %>% length
```

After trying and failing to get a (truly) free, open-source, reproducible way to get conversion rates, we ultimately decided to use the conversion rate of 100 Million Chinese Yuan (CNY) to USD, which at a rate of 1 CNY to 1 USD of 0.137781 as of July 11, 2024 is: 13,778,100.00 (USD)
- sources: [wise](https://wise.com/us/currency-converter/cny-to-usd-rate?amount=100000000), [Google Finance](https://www.google.com/finance/quote/CNY-USD?sa=X&ved=2ahUKEwiwt9CxgaCHAxWKle4BHdMZCxcQmY0JegQIBxAp)


According to the US Bureau of Labor Statistics, \$1 USD in June 2024 has the same buying power as \$0.76 in June of 2015 [conversion link & source](https://data.bls.gov/cgi-bin/cpicalc.pl?cost1=1.00&year1=202406&year2=201506) (they didn't have data for July of this year, and thankfully the 1 month average of CNY to USD was relatively stable around 0.1378). This means that once we convert the historic CNY to 2024 USD, we can convert those 2024 USD values back to the Constant 2015 USD (which the rest of our GDP data is in) using this conversion rate. Alternatively, we could use the `priceR::adjust_for_inflation()` function. However, the cny_to_usd rate is hard-coded, so for now we'll continue to use the hard-coded approach for adjusting the CNY --> USD current --> USD 2015 values. We will use the `priceR::adjust_for_inflation()` to adjust the USD current --> USD 2015 constant values.


```{r standardize_china_value}
# 100 million yuan = 13,778,100.00 (USD)
h_mil_cny_to_usd <- 13778100 # update this appropriately, or ideally find a reproducible conversion rate method and implement

# convert Chinese Yuan to USD
nbsc_usd <- nbsc_tidy %>% 
  dplyr::mutate(tour_value = case_when(
    indicators == tourism_categories[1] ~ tour_value * 1000000, # USD million --> USD (1)
    indicators == tourism_categories[2] ~ tour_value * h_mil_cny_to_usd #(CNY hundred million --> USD (1))
  ))

# now we have domestic tourism value in 2024 USD and 
# international tourism in current USD ($ year = year column value in data frame)

# ---- adjust for inflation, standardize to 2015 USD ----
nbsc_usd_adjusted <- nbsc_usd %>% 
  # optional: tidy up indicator names
  # mutate(indicators = case_when(
  #   indicators == tourism_categories[1] ~ "Foreign Exchange Earnings from International Tourism",
  #   indicators == tourism_categories[2] ~ "Earnings from Domestic Tourism"
  dplyr::mutate(usd = case_when(
    # international: convert Current USD to 2015 Constant US$ 
    indicators == tourism_categories[1] ~ priceR::adjust_for_inflation(price = tour_value, from_date = year, country = "US", to_date = 2015),
    
    # domestic: (2024 USD --> 2015 USD)
    indicators == tourism_categories[2] ~ priceR::adjust_for_inflation(price = tour_value,
                                                                       from_date = current_year, # or hard code this to whatever year's conversion rate you're using for CNY to USD
                                                                       country = "US", to_date = 2015)
    
  ))


# Check: 2015 years should match up
int_2015 <- nbsc_usd_adjusted %>% 
  dplyr::filter(year == 2015, indicators == tourism_categories[1])

int_2015$tour_value == int_2015$usd


# now that everything is in the same units (Constant 2015 US$), we can go ahead and aggregate the data to get a combined tourism value from international and domestic tourism earnings.

# ---- aggregate ----
china_usd_value <- nbsc_usd_adjusted %>% 
  # for each year,
  dplyr::group_by(year) %>% 
  # sum values !
  dplyr::summarize(usd = sum(tour_value, usd, na.rm = T)) %>% 
  # add descriptive columns for joining
  dplyr::mutate(geo_area_name = "China") %>% 
  # order columns
  dplyr::select(geo_area_name, year, usd)

```

#### Plot China Tourism Value

```{r}
library(ggplot2) # to avoid namespacing
ggplot(data = china_usd_value, 
       aes(x = as.numeric(year), 
           y = usd)) +
  # pulled hexcode from Chinese flag
  geom_point(color = "#EE1C25") +
  geom_line(color = "#EE1C25") +
  scale_x_continuous(breaks = c(date_range)) +
  # make y-axis more legible
  scale_y_continuous(labels = scales::label_currency(scale = 0.000000001,
                                                     suffix = "B"
                                                     # $30.00B --> $30B
                                                     # scale_cut = scales::cut_long_scale()
  )) +
  # set base themex
  theme_bw() +
  # adjust labels
  labs(title = paste0("Tourism Value in mainland China ", "(",
                      start_year,
                      "-", stop_year, ")"),
       subtitle = "Data Sources: UNWTO, World Bank",
       x = "Year",
       y = "Tourism Value (Constant 2015 US$)") +
  # tidy up aesthetic elements
  theme(
    axis.text.x = element_text(angle = 40, vjust = 0.8, hjust = 0.9),
    axis.title.x = element_text(margin = margin(t = 1.2, b = 0.2, unit = "lines")),
    axis.title.y = element_text(margin = margin(l = 0.5, r = 0.5, unit = "lines")),
    panel.grid.minor.x = element_blank(),
    plot.title = element_text(margin = margin(t = 0.5, b = 0.5, unit = "lines")),
    plot.subtitle = element_text(margin = margin(b = 1, unit = "lines"))
  )
```

Here we can see that China's earnings from tourism far exceed any of the values we've seen before, surpassing 1.6 Trillion by 2019. These numbers will be slightly higher once we add on the values for Macao and Hong Kong.




# Coastal Tourism

## Finding coastal tourism values from total tourism values

-   read in data on coastal population counts and total population per region 
-   create dataframe of proportion of coastal population per region
-   multiply percentage decimal by total tourism value to get approximation for coastal tourism 

Resources: <https://dcl-wrangle.stanford.edu/pivot-advanced.html> used for regular expression implementation

```{r}
library(tidyverse)
# read in coastal population proportion from PLACE
coastal_pop_prop_raw <- read_csv(here::here(raw_data_dir, "SEDAC_CIESIN", data_dir_version_year, "nagdc-population-landscape-and-climate-estimates-v3-csv", "nagdc-population-landscape-and-climate-estimates-version-3.csv"))

# ---- preliminary cleaning & filtering ----
coastal_prop <- coastal_pop_prop_raw %>% 
  janitor::clean_names() %>% 
  # filter to 100km coastal proximity
  dplyr::filter(theme_variable %in% c("COASTAL PROXIMITY: 100KM ZONE: 100km zone")) %>% 
  # select relevant columns
  dplyr::select(c(iso3v10, countryname, designationid:incomegroup)) %>% 
  # rename population (not pct) columns to prepare for pivoting
  dplyr::rename_with(
    # use a regular expression to detect the YYYY pattern (and end after those years, avoiding pct columns)
    .cols = matches("^population\\d{4}$"),
    .fn = ~ paste0(., "_count") # add _count to the end of those column names
  )

# ---- tidy ----
coastal_prop_tidy <- coastal_prop %>% 
  # first pivot: longer --> collapse cols into "name": populationYYYY_count|pct and values into "value"
  tidyr::pivot_longer(
    cols = starts_with("population"),
    names_to = "name",
    values_to = "value"
  ) %>%
  # create "year" column and simplified "type" (count or pct) column
  dplyr::mutate(
    # use a regular expression to pull out the YYYY values
    year = as.numeric(str_extract(name, "\\d{4}")),
    # if "_count" is detected, rename to "count", else "pct"
    type = if_else(str_detect(name, "_count$"), "count", "pct")
  ) %>%
  # drop old name column (we've already extracted the relevant information)
  dplyr::select(-name) %>%
  # second pivot: wider --> values into "population_count" and "population_pct"
  tidyr::pivot_wider(
    names_from = type,
    values_from = value,
    names_prefix = "population_"
  )

# there should now be three rows for each designated area (urban and rural) for each country,
# as there are three years (1990, 2000, 2010)

# note: there are two designations: rural and urban
# so we're going to have to aggregate these to get a total proportion

# # investigating values for 1 country
# coastal_2010_pop_subset <- coastal_prop_tidy %>% 
#   dplyr::filter(year == 2010) %>% 
#   dplyr::select(c(country_name = countryname, designation = designationname, year, population_count, population_pct))
# 
# coastal_2010_pop_subset %>% filter(country_name %in% c("United States of America"))
```

Okay! Now that the data is tidy, we need to aggregate the coastal population percentages (Rural + Urban = Total Coastal) per country per year. We could also just filter to year == 2010, since we're only going to be using that year's data, but I want to filter that out as late as possible in case future years decide to incorporate updated data or use 1990 and 2000 values to make projections beyond 2010. 


#### Coastal population

Aggregate by `country_name` to get total coastal population (count and percent) in 2010. We'll use this to calculate a fixed coastal population proportion multiplier to estimate coastal tourism value.

```{r}
# ---- create subset for fixed multiplier calculation ----
coastal_pop_subset <- coastal_prop_tidy %>% 
  dplyr::select(c(country_name = countryname, designation = designationname, year, population_count, population_pct))


# ---- find estimated total coastal population ----
coastal_pop <- coastal_pop_subset %>% 
  dplyr::group_by(country_name, year) %>% 
  dplyr::summarise(coastal_pop = sum(population_count, na.rm = TRUE),
                   coastal_pct = sum(population_pct, na.rm = TRUE),
                   .groups = "keep") 
  # note: the raw data has zeros instead of NAs in many cases
  
# check to see if this step worked
(coastal_pop %>% filter(country_name %in% c("United States of America")) %>% 
    knitr::kable(format = "markdown", booktabs = TRUE)) %>% 
  kableExtra::row_spec(0, bold = TRUE) %>% 
  kableExtra::kable_styling("striped", full_width = FALSE) 

# ---- create proportion multiplier ---- (to estimate coastal proportion of tourism value)
coastal_multipliers <- coastal_pop %>% 
  dplyr::mutate(coastal_proportion = coastal_pct / 100)


# inspect data
(coastal_multipliers %>% filter(country_name == "Guam")) %>% 
  knitr::kable(format = "markdown", booktabs = TRUE) %>% 
  kableExtra::row_spec(0, bold = TRUE) %>% 
  kableExtra::kable_styling("striped", full_width = FALSE) 

# note: data gap in 2010 -- clear data for 1990 and 2000, but "0" for 2010... it's not like Guam's population suddenly vanished within 100km of the coast
```

To address these case-specific datagaps for countries with "0" values that should actually be "NA", we'll replace those zeroes with NA placeholders, then gap fill using `na.approx` and `rule = 2` to copy over the 2000 value to 2010. Methodologically this shouldn't be adding major errors, as coastal population levels are relatively stable over this type of limited time frame.

*pseudo code:*

-   for each `country_name` (group by)
(do the rest in a mutate(case_when))
    -   if coastal_proportion != 0 in 1990 and/or 2000 
    -   AND coastal_proportion == 0 in 2010
    -   replace coastal_prportion value of 0 with NA for 2010 
    
  then gapfill for those NAs (goal is to copy over 2000 value for missing/zero 2010 value)


```{r}
# ---- gapfilling prep ----
coastal_fixed <- coastal_multipliers %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(country_name) %>% 
  dplyr::mutate(coastal_prop_fix = case_when(
    # for each country, if the year is 2010 and 
    year == 2010 & 
      # coastal_proportion value is 0 and
      coastal_proportion == 0 &
      # if the coastal_proportion values in 1990 and 2000 are not zero, fill 2010 value with NA
      any(coastal_proportion[year %in% c(1990, 2000)] != 0) ~ NA_real_,
    # otherwise, keep original coastal_proportion value
    .default = coastal_proportion
  )
  ) %>% 
  dplyr::ungroup()

# check to see if this worked ----
# proper NA filling:
coastal_fixed %>% filter(country_name == "Guam") %>% 
  knitr::kable(format = "markdown", booktabs = TRUE) %>% 
  kableExtra::row_spec(0, bold = TRUE) %>% 
  kableExtra::kable_styling("striped", full_width = FALSE)
# nice! we can see "NA" in 2010's coastal_prop_fixed column

# maintaining appropriate zeroes for landlocked countries
coastal_fixed %>% filter(country_name == "Afghanistan") %>% 
  knitr::kable(format = "markdown", booktabs = TRUE) %>% 
  kableExtra::row_spec(0, bold = TRUE) %>% 
  kableExtra::kable_styling("striped", full_width = FALSE)
# great! zeroes are maintained when appropriate

# ---- gapfilling ----
# for countries that have 1990 and 2000 data but not 2010 data, gapfill 2010 values with 2000 values
coastal_gf <- coastal_fixed %>% 
  dplyr::group_by(country_name) %>% 
  # interpolate (fill missing values between 2 values)
  dplyr::mutate(coastal_prop_gf = zoo::na.approx(coastal_prop_fix, # using values in this column
                                       na.rm = FALSE, # don't replace (internal) NAs in new column that can't be approximated
                                       rule = 2 # uses closest data extreme to extrapolate for leading and trailing NAs
  )) %>% 
  dplyr::ungroup()

# check:
coastal_gf %>% dplyr::filter(country_name == "Guam") %>% 
  knitr::kable(format = "markdown", booktabs = TRUE) %>% 
  kableExtra::row_spec(0, bold = TRUE) %>% 
  kableExtra::kable_styling("striped", full_width = FALSE)
# great! coastal_prop_gf is now 1 for 2010 
```


Basic plot to visually inspect data

```{r}
coastal_pct_plot <- plotly::plot_ly(data = coastal_gf,
                                     x = ~year,
                                     y = ~coastal_prop_gf,
                                     color = ~country_name, 
                                     type = "scatter", mode = "lines") %>% 
  # update layout: text, margins
  plotly::layout(title = "Coastal Population (% per region)",
                 margin = m, # set margins
                 xaxis = list(title = "Year"),
                 yaxis = list(title = "Coastal Population % (gapfilled)"))

coastal_pct_plot
```

A true spaghetti plot. Wow. 

Awful visuals aside, this seems pretty solid -- we'd expect coastal population % to be relatively stable over this time frame.


Now we can make subsets to apply to our tourism value data.

We have a subset of Hong Kong and Macao tourism value separated out as `macao_hk_value`. We should apply appropriate multipliers to this subset and to the China subset created with the Bureau of Statistics of China data. After the multipliers have been applied, we can then aggregate their values within the greater OHI region classification of China. 

**Next steps:**

-   create coastal subsets for (1) Hong Kong + Macao (`macao_hk_coastal`), (2) China (`china_coastal`), (3) no China, HK, or Macao (`no_china_coastal`)
-   run `name_2_rgn` on (3) no-china subset
    -   address duplicates, rename, aggregate, etc.
    
-   drop "year" column of coastal subsets, see if this works for joining subsets. If not, create new years df, apply to coastal subset so that multiplier is copied along range of years for each country.

-   join (1) Macao + HK coastal proportion subset and tourism value subset, implement multipliers
-   join (2) China coastal subset and China tourism value subset, implement multiplier
-   join Macao + HK coastal tourism value + China coastal tourism value, aggregate to get total China coastal tourism value

-   join (3) no China, HK, or Macao coastal proportion subset with appropriate tourism value subset; prep + implement multiplier to get coastal tourism value

*Final:*

-   join USA coastal tour value + China coastal tour value + everything else coastal tour value
-   plot along the way ^^^
-   prep for export
-   save to `int` as `.csv`

```{r}
# ---- make subsets ----

# Macao + Hong Kong
macao_hk_coastal <- coastal_gf %>% 
  dplyr::filter(country_name %in% c("Macao", "Hong Kong")) %>% 
  dplyr::select(country_name, year, coastal_prop_gf) %>% 
  dplyr::filter(year == 2010)
# note: both have proportions of 1 (100% of population lives within 100km of coast)
# this means that we can actually just add their full tourism values to the coast-adjusted tourism values for China

# China
china_coastal <- coastal_gf %>% 
  dplyr::filter(country_name %in% c("China")) %>% 
  dplyr::select(country_name, year, coastal_prop_gf) %>% 
  dplyr::filter(year == 2010)

# without China, Hong Kong, or Macao (to prep for running name_2_rgn)
no_china_coastal <- coastal_gf %>% 
  dplyr::filter(!country_name %in% c("China", "Hong Kong", "Macao")) %>% 
  dplyr::select(country_name, year, coastal_prop_gf)
```


Run `name_2_rgn`

```{r}
# ---- run name_2_rgn on coastal subset without China ----
coastal_rgn <- ohicore::name_2_rgn(
  df_in = no_china_coastal, 
  fld_name = "country_name",
  flds_unique = c("year")
)

# ---- issues to address ----
# "These data were removed for not having any match in the lookup tables:"
# isle of man 
# korea 
# netherland antilles       
# saint vincent            
# svalbard       
# western samoa 

# ---- find duplicates ----
coastal_duplicates <- coastal_rgn[duplicated(coastal_rgn[, c("rgn_name", "year")]),]
#unique(coastal_duplicates$country_name)
coastal_dup_rgns <- c(unique(coastal_duplicates$rgn_name))

#length(unique(gdp_rgn$rgn_name))

# Guadeloupe and Martinique
# Northern Mariana Islands and Guam
# Puerto Rico and Virgin Islands of the United States

coastal_rgn %>% dplyr::filter(rgn_name %in% c("Guadeloupe and Martinique"))
# both are 1, so we can aggregate by taking the mean proportion value per year, grouping by rgn_name, rgn_id, and year

coastal_rgn %>% dplyr::filter(rgn_name %in% c("Northern Mariana Islands and Guam"))
# both are equal to 0 (the coastal pop dataset did not have data on these regions in 2010, but the coastal population percent was 100% for both regions in 1990 and 2000, so we will set these proportions equal to 1 in our next aggregation step by taking the mean of both 1s

coastal_rgn %>% dplyr::filter(rgn_name %in% c("Puerto Rico and Virgin Islands of the United States"))
# great! for all of these, the proportion is 1 in both regions, so we can just use a mean to aggregate

# ---- fix names ----
no_china_coastal_fix <- no_china_coastal %>% 
  dplyr::select(country_name, year, coastal_prop_gf) %>% 
  dplyr::mutate(country_name = case_when(
    country_name == "Korea" ~ "South Korea",
    country_name == "Netherland Antilles" ~ "Curacao",
    country_name == "Saint Vincent" ~ "Saint Vincent and the Grenadines",
    country_name == "Western Samoa" ~ "Samoa", #OHI has Samoa (WSM) and American Samoa (ASM)
    .default = country_name
  ))

# ---- run name_2_rgn again ----
coastal_rgn <- ohicore::name_2_rgn(
  df_in = no_china_coastal_fix, 
  fld_name = "country_name",
  flds_unique = c("year")
)

# Isle of Man and Svalbard are still being removed. Check w Mel (COME BACK) about Svalbard being agged with Norway


# ---- aggregate ----
coastal_rgn_agg <- coastal_rgn %>% 
  dplyr::mutate(rgn_id = as.character(rgn_id)) %>% # set data type
  dplyr::ungroup() %>% 
  dplyr::group_by(rgn_id, rgn_name, year) %>% 
  # taking the mean 
  dplyr::summarize(coastal_prop_gf = mean(coastal_prop_gf, na.rm = TRUE), .groups = "drop") %>% 
  dplyr::filter(rgn_name != "United States") # drop USA because we have separate coastal data for it

```

#### Coastal joins 

**Next steps:**

*joining:*
-   join (1) Macao + HK coastal proportion subset and tourism value subset, implement multipliers
-   join (2) China coastal subset and China tourism value subset, implement multiplier
-   join Macao + HK coastal tourism value + China coastal tourism value, aggregate to get total China coastal tourism value
-   join (3) no China, HK, or Macao coastal proportion subset with appropriate tourism value subset; prep + implement multiplier to get coastal tourism value

```{r}
# ---- Macao + HK coastal tourism ----
# we don't even really need to do this, since all of the multipliers for Macao and Hong Kong = 1, but I'm creating the infrastructure for it in case we use a different coastal population metric in the future (which may impact the multiplier value)
# prep coastal data for joining
m_hk_prep <- macao_hk_coastal %>% 
  dplyr::select(-year) %>% 
  # match naming conventions across dataframes
  dplyr::mutate(country_name = case_when(
    country_name == "Hong Kong" ~ "Hong Kong SAR, China",
    country_name == "Macao" ~ "Macao SAR, China",
  )) %>% 
  dplyr::group_by(country_name, coastal_prop_gf) %>% 
  # fill with full year range for joining
  dplyr::reframe(year = seq(start_year, stop_year))

# join with tourism value subset
macao_hk_coastal_tour <- dplyr::full_join(macao_hk_value, m_hk_prep,
                                          by = c("geo_area_name" = "country_name", "year")) %>% 
  # multiply total tourism value (constant 2015 USD) by coastal population proportion
  dplyr::mutate(coastal_tour_value = (tour_value * coastal_prop_gf)) %>% 
  dplyr::select(geo_area_name, year, coastal_tour_value)

# ---- mainland China coastal tourism ----
# prep for joining
china_coastal_prep <- china_coastal %>% 
  dplyr::select(-year) %>% 
  dplyr::group_by(country_name, coastal_prop_gf) %>% 
  # fill with full year range for joining
  dplyr::reframe(year = seq(start_year, stop_year))

# join with tourism value subset
china_coastal_tour <- dplyr::full_join(china_usd_value, china_coastal_prep,
                                          by = c("geo_area_name" = "country_name", "year")) %>% 
  # multiply total tourism value (constant 2015 USD) by coastal population proportion
  dplyr::mutate(coastal_tour_value = (usd * coastal_prop_gf)) %>% 
  dplyr::select(geo_area_name, year, coastal_tour_value)
```

Now we can join these newly created China & Macao + Hong Kong coastal tourism value data frames. Then, we'll run `name_2_rgn` and aggregate values to get combined tourism values for China as an OHI region. We'll call this `china_coastal_tour_agg`.

```{r}
# ---- total China coastal tourism ----

# ---- join ----
china_value_join <- dplyr::full_join(x = china_coastal_tour, y = macao_hk_coastal_tour,
                                     by = c("geo_area_name", "year","coastal_tour_value"))

# ---- run ohicore name_2_rgn function ----

china_rgn <- ohicore::name_2_rgn(
  df_in = china_value_join, 
  fld_name = "geo_area_name",
  flds_unique = c("year")
)

# as expected, we get a "DUPLICATES found" warning. Now that the rgn_name and rgn_id have been added to our data frame, we can use those to aggregate by region

# ---- aggregate for OHI region cohesion ----
china_coastal_tour_agg <- china_rgn %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(rgn_name, rgn_id, year) %>% 
  # get aggregate coastal tourism value
  dplyr::summarize(coastal_tour_value = sum(coastal_tour_value, na.rm = T),
                   .groups = "drop") %>% 
  dplyr::mutate(rgn_id = as.character(rgn_id)) # fix data type

```

```{r}
china_coastal_tour_plot <- plotly::plot_ly(data = china_coastal_tour_agg,
                                     x = ~year,
                                     y = ~coastal_tour_value,
                                     color = ~rgn_name, 
                                     type = "scatter", mode = "lines") %>% 
  # update layout: text, margins
  plotly::layout(title = paste0("Coastal Tourism Value in Constant 2015 US$ (", start_year, "-", stop_year, ")"),
                 margin = m, # set margins
                 xaxis = list(title = "Year"),
                 yaxis = list(title = "Coastal Tourism Value (constant 2015 USD)"))

china_coastal_tour_plot
```



-   join (3) no China, HK, or Macao coastal proportion subset with appropriate tourism value subset; prep + implement multiplier to get coastal tourism value

```{r}
# ---- coastal tourism (excluding China regions, USA) ----
# prep coastal prop subset for joining
coastal_rgns_prep <- coastal_rgn_agg %>% 
  # filter to 2010 (we'll copy these values for the full time range)
  dplyr::filter(year == 2010) %>% 
  dplyr::select(-year) %>% 
  dplyr::group_by(rgn_id, rgn_name, coastal_prop_gf) %>% 
  # fill with full year range for joining
  dplyr::reframe(year = seq(start_year, stop_year))

# join with tourism value subset
coastal_subset_tour <- dplyr::full_join(nc_tourism_value, coastal_rgns_prep,
                                          by = c("rgn_id", "rgn_name", "year")) %>% 
  # multiply total tourism value (constant 2015 USD) by coastal population proportion
  dplyr::mutate(coastal_tour_value = (tour_value * coastal_prop_gf)) %>% 
  dplyr::select(rgn_id, rgn_name, year, coastal_tour_value) %>% 
  dplyr::ungroup()

```

```{r , eval=FALSE}
# preliminary plot to visually inspect data post-implementation of multiplier

coastal_subset_tour_plot <- plotly::plot_ly(data = coastal_subset_tour,
                                     x = ~year,
                                     y = ~coastal_tour_value,
                                     color = ~rgn_name, 
                                     type = "scatter", mode = "lines") %>% 
  # update layout: text, margins
  plotly::layout(title = "Coastal Tourism Value in Constant 2015 US$ (2008-2019)",
                 margin = m, # set margins
                 xaxis = list(title = "Year"),
                 yaxis = list(title = "Coastal Tourism Value (constant 2015 USD)"))

coastal_subset_tour_plot
```


Now we are ready to join our coastal tourism value subsets (once we process the USA coastal tourism data, which we'll do in the chunks below). After processing the United States coastal tourism value data, we will: 

-   join USA coastal tour value + China coastal tour value + everything else coastal tour value
-   prep for export
-   save to `int` as `.csv`

-----------


## Coastal Tourism: The United States of America

This dataset contains coastal tourism values (USD, current and adjusted) for states in the United States of America from the Economics: National Ocean Watch (ENOW).

The data currently includes states that border/contain the Great Lakes, so we'll need to filter those out. To do that, we will:

-   clean the data and select tourism sector GDP data
-   make two subsets: one that contains only the great lakes states and one that only contains the total coastal aggregate values
-   subtract the great lakes subset values from the total to obtain the true coastal tourism GDP values

```{r}
# ---- Preliminary cleaning & tidying ----
enow_usa_clean <- enow_usa_raw %>% 
  janitor::clean_names() %>% 
  dplyr::select(geo_name, geo_scale, year, ocean_sector, ocean_industry, gdp, real_gdp) %>% 
  dplyr::filter(ocean_sector %in% c("Tourism and Recreation")) %>% 
  dplyr::filter(ocean_industry %in% c("Total"))

# check for year of inflation adjustment real_gdp 
enow_usa_clean %>% dplyr::filter(gdp == real_gdp) %>% head()

# now we know that it has been adjusted to 2012!
adjusted_year <- 2012 # update this if the adjusted date changes

# ---- Subsetting: Coastal USA and Great Lakes states ----

# Coastal total subset 
coastal_total <- enow_usa_clean %>% 
  dplyr::filter(geo_name %in% c("Coastal USA")) %>% # alternatively, you could filter to geo_scale == "National"
  # remove redundant columns after double checking that we filtered properly earlier
  dplyr::select(-c(geo_scale, ocean_sector, ocean_industry))

# Great Lakes subset
great_lakes <- enow_usa_clean %>% 
  dplyr::filter(geo_name %in% c("Illinois", "Indiana",
                         "Michigan", "Minnesota",
                         "Ohio", "Wisconsin",
                         "Pennsylvania")) %>% # excluding  "New York" because it is also coastal
  dplyr::select(-c(geo_scale, ocean_sector, ocean_industry))


# ---- Aggregate: get great lakes total tourism value ----
great_lakes_total <- great_lakes %>% 
  dplyr::group_by(year) %>% 
  dplyr::summarize(gl_gdp = sum(gdp),
            gl_real_gdp = sum(real_gdp))

# ---- Calculate true coastal tourism value ----
coastal_lakes_join <- dplyr::full_join(coastal_total, great_lakes_total,
                                       by = "year")

# subtract great lakes values from coastal total values
true_coastal_value <- coastal_lakes_join %>% 
  dplyr::mutate(coastal_tour_gdp = (gdp - gl_gdp),
         coastal_tour_real_gdp = (real_gdp - gl_real_gdp))

# check:
if (sum((true_coastal_value$coastal_tour_gdp == (true_coastal_value$gdp - true_coastal_value$gl_gdp)) / nrow(true_coastal_value))) {
  print("Subtraction successful!")
} else {
  print("Subtraction failed. New column is not the difference between expected columns. Please double-check your methods.")
}


# ---- Adjust for inflation & Standardize ----
# if we're not fully confident that the dataset's inflation adjustment matches the inflation adjustment methods that we use throughout this subgoal (priceR::adjust_for_inflation()), we can use the GDP column and convert to 2015 constant USD. We could also convert from 2012 adjusted to 2015 adjusted. The following code can be altered for either method.



# standardize inflation adjustment to 2015 constant USD for joining with global tourism value dataframe
usa_coastal_adj <- true_coastal_value %>% 
  dplyr::mutate(coastal_tour_value = priceR::adjust_for_inflation(
    price = coastal_tour_gdp, # or: coastal_tour_real_gdp
    from_date = year, # or: adjusted_year (set to 2012 earlier)
    country = "US",
    to_date = 2015))

# for gdp (not real_gdp) method: check
usa_check_subset <- usa_coastal_adj %>% 
  dplyr::filter(year == 2015) %>% # or change to whichever year you've adjusted the data to for inflation
  dplyr::select(year, coastal_tour_gdp, coastal_tour_value)

if (usa_check_subset$coastal_tour_gdp == usa_check_subset$coastal_tour_value) {
  print(paste("USA Coastal tourism values have been successfully adjusted to", usa_check_subset$year, "USD."))
} else {
  print("Adjustment for inflation did not match for the selected year. Please check that the data has been subsetted to the year of adjustment and try again.")
}


# ---- Prep for joining with full coastal tourism dataset ----
usa_coastal_prep <- usa_coastal_adj %>% 
  dplyr::mutate(country_name = "United States of America") %>% 
  dplyr::select(country_name, year, coastal_tour_value)

# run ohicore name_2_rgn
usa_coastal_rgn <- ohicore::name_2_rgn(usa_coastal_prep,
                                       fld_name = "country_name",
                                       flds_unique = "year")

# select columns for joining
# full because we haven't filtered to the standardized date range
usa_coastal_tourism_full <- usa_coastal_rgn %>% 
  dplyr::select(rgn_id, rgn_name, year, coastal_tour_value)
```


Preliminary plot to inspect data

```{r}
ggplot(data = usa_coastal_tourism_full, 
       aes(x = year, y = coastal_tour_value)) +
  # old glory red hex code from flag
  geom_line(color = "#B31942") +
  # old glory blue hex code from flag
  geom_point(color = "#0A3161") + 
  # show_col(viridis::viridis(6))
  #scale_x_continuous(breaks = c(date_range)) +
  # make y-axis more legible
  scale_y_continuous(labels = scales::label_currency(scale = 0.000000001,
                                                     suffix = "B",
                                                     # $30.00B --> $30B
                                                     scale_cut = cut_long_scale())) +
  theme_bw() +
  # update labels
  labs(title = paste0("Coastal Tourism Value in the United States of America ", "(2005-2021)"),
       subtitle = "Data Source: ENOW",
       x = "Year",
       y = "Tourism Value (Constant 2015 US$)",
       color = "Region") +
  # customize theme elements
  theme(
    axis.text.x = element_text(margin = margin(t = 0.8, unit = "lines")),
    axis.title.x = element_text(margin = margin(t = 1.2, b = 0.2, unit = "lines")),
    axis.title.y = element_text(margin = margin(l = 0.5, r = 0.5, unit = "lines")),
    panel.grid.minor.x = element_blank(),
    plot.title = element_text(margin = margin(t = 0.5, b = 0.5, unit = "lines")),
    plot.subtitle = element_text(margin = margin(b = 1, unit = "lines")))
```

This seems to be fairly reflective of the $143 Billion value associated with US coastal tourism according to [NOAA](https://coast.noaa.gov/states/fast-facts/tourism-and-recreation.html), and the sharp fall in 2020 reflects the trend we expect to see due to COVID-19 Pandemic impacts on tourism globally.

## Final Joins: Total Coastal Tourism

Now, let's filter to the date range of the rest of the data and join with the subset excluding China & USA and the China aggregate subset to get a full coastal tourism value dataset!
```{r}
# filter USA data
usa_coastal_tourism <- usa_coastal_tourism_full %>% 
  filter(year %in% c(date_range)) %>% 
  mutate(rgn_id = as.character(rgn_id)) # fix data type for joining

# optional: check that year filtering worked
#max(usa_coastal_tourism$year) == stop_year

# ---- join coastal tourism datasets ----
# join USA + China aggregate:
usa_china_coastal <- dplyr::full_join(usa_coastal_tourism, china_coastal_tour_agg,
                                      by = join_by("rgn_id", "rgn_name", "year", "coastal_tour_value"))

# join with final coastal tourism subset
coastal_tourism_join <- dplyr::full_join(coastal_subset_tour, usa_china_coastal,
                                         by = join_by("rgn_id", "rgn_name", "year", "coastal_tour_value")) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(rgn_id = as.numeric(rgn_id)) # prep for joining with OHI regions downstream

# use this copy for exporting if not joining with OHI regions upstream (see code chunk below)
coastal_tourism_full <- coastal_tourism_join 
```


Archived (because we do this downstream in `eco_usd_adj.Rmd`)
```{r, eval=FALSE}
# # ---- join OHI regions with years df ----
# # expand OHI regions to have sequence of years for joining
# ohi_region_yrs <- region_names %>% 
#   # expand() generates all combinations of variables found in a dataset
#   # nesting() finds combinations of rgn_id & rgn_name already present in the df
#   tidyr::expand(nesting(rgn_id, rgn_name), # note: you can't expand on a grouping column
#                 year = start_year:stop_year) %>% # within each group combination, add sequence of years in new "year" column
#   dplyr::arrange(rgn_id, year)
# 
# # join OHI regions with full coastal tourism df
# coastal_tourism_full <- dplyr::full_join(ohi_region_yrs, coastal_tourism_join,
#                                          by = join_by("rgn_id", "rgn_name", "year")) %>% 
#   dplyr::select(rgn_id, rgn_name, year, coastal_tour_value) %>% 
#   dplyr::ungroup()

```


```{r}
# preliminary plotting to investigate

coastal_tour_plot <- plotly::plot_ly(data = coastal_tourism_full,
                                     x = ~year,
                                     y = ~coastal_tour_value,
                                     color = ~rgn_name, 
                                     type = "scatter", mode = "lines") %>% 
  # update layout: text, margins
  plotly::layout(title = "Coastal Tourism Value",
                 margin = m, # set margins
                 xaxis = list(title = "Year"),
                 yaxis = list(title = "Tourism Value (constant 2015 USD)", 
                              tickprefix = "$"))

coastal_tour_plot
```

Intuition check: does it make sense for China's values to be so high? 
Yes! Their total tourism in 2019 was roughly $1.6 trillion (2015 USD)

## Implementing sector multipliers

Refer to the OHI Methods or [Ben Halpern's Supplementary Information](https://static-content.springer.com/esm/art%3A10.1038%2Fnature11397/MediaObjects/41586_2012_BFnature11397_MOESM79_ESM.pdf) **(page 29)** for the multipliers to apply towards revenue values by sector for developing versus developed countries.

There are actually no multipliers for the tourism sector. 


# Saving intermediate data 

Prep for saving & save to `int` folder

```{r}
#---- Prepping data for int saving ----
tour_revenue_int <- coastal_tourism_full %>% 
  rename(usd = coastal_tour_value) %>% 
  mutate(
    unit = "USD (1)",
    sector = "tour",
    # used in the inflation adjustment calculation downstream
    usd_yr = 2015 # because the tourism values are in "Constant 2015 US$"
  ) %>% 
  select(rgn_id, rgn_name, year, usd, unit, sector, usd_yr) %>% 
  ungroup()

#str(tour_revenue_int) # check datatypes before writing out

# ---- Write out to int folder ----
#write_csv(tour_revenue_int, here::here(int_dir, "eco_tour_usd_pre.csv"))
```


